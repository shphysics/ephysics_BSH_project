{"cells":[{"cell_type":"code","source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment2/'\n","FOLDERNAME = '/content/drive/MyDrive/Stanford Research/honor thesis for Ephysics/ephysics project/'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","# This downloads the CIFAR-10 dataset to your Drive\n","# if it doesn't already exist.\n","# %cd /content/drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n","# !bash get_datasets.sh\n","# %cd /content/drive/My\\ Drive/$FOLDERNAME"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpKXzIWAoxjt","executionInfo":{"status":"ok","timestamp":1683818608813,"user_tz":420,"elapsed":19082,"user":{"displayName":"William Cai","userId":"15768919470381419406"}},"outputId":"88c97386-16b4-479b-d20a-ea872ee94784"},"id":"zpKXzIWAoxjt","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"id":"6a97252d","metadata":{"id":"6a97252d","executionInfo":{"status":"ok","timestamp":1683818798066,"user_tz":420,"elapsed":330,"user":{"displayName":"William Cai","userId":"15768919470381419406"}}},"outputs":[],"source":["# !pip install pymatgen\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import style\n","\n","import sklearn\n","import csv\n","import pandas as pd\n","# import pymatgen as mg\n","import random\n","import os\n","from bisect import bisect_left   \n","from sklearn import preprocessing\n","from sklearn.utils import Bunch\n","from sklearn import svm\n","# from mp_api.client import MPRester\n","\n","#from sklearn import datasets, svm\n","from sklearn.svm import SVC\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.preprocessing import StandardScaler\n","\n","import time\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split, KFold\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import StratifiedKFold\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_recall_curve, confusion_matrix\n","\n","\n","style.use(\"ggplot\")"]},{"cell_type":"code","execution_count":3,"id":"e4c8578b","metadata":{"id":"e4c8578b","executionInfo":{"status":"ok","timestamp":1683818613742,"user_tz":420,"elapsed":13,"user":{"displayName":"William Cai","userId":"15768919470381419406"}}},"outputs":[],"source":["#shuffles dataset\n","def format_dataset(X, y, size = -1):\n","    random.seed(a=5)\n","    length = np.size(y)\n","    indices = np.arange(length)\n","    np.random.shuffle(indices)\n","    new_X = []\n","    new_y = []\n","    for x in indices:\n","        new_X.append(X[x])\n","        new_y.append(y[x])\n","    if size == -1:\n","        return Bunch(data=new_X, target=new_y)\n","    return Bunch(data=new_X[0:size], target=new_y[0:size])\n","\n","#pos, neg are lists\n","def get_labels(pos, neg):\n","    y = []\n","    for i in range(len(pos)):\n","        y.append(1)\n","    for i in range(len(neg)):\n","        y.append(0)\n","    return np.array(y)\n","\n","\n","def calculate_classification_rates(predictions, labels):\n","    \"\"\"\n","    Calculates the classification rates based on the predictions and labels.\n","\n","    Args:\n","    - predictions: NumPy array of predicted values (shape: [n_samples])\n","    - labels: List of true labels (length: n_samples)\n","\n","    Returns:\n","    - true_positive_rate: Float, true positive rate (TPR) or sensitivity\n","    - false_positive_rate: Float, false positive rate (FPR)\n","    - true_negative_rate: Float, true negative rate (TNR) or specificity\n","    - false_negative_rate: Float, false negative rate (FNR)\n","    \"\"\"\n","\n","    # Convert labels to NumPy array for easier manipulation\n","    labels = np.array(labels)\n","\n","    # Calculate the number of true positive, false positive, true negative, and false negative\n","    true_positive = np.sum((predictions == 1) & (labels == 1))\n","    false_positive = np.sum((predictions == 1) & (labels == 0))\n","    true_negative = np.sum((predictions == 0) & (labels == 0))\n","    false_negative = np.sum((predictions == 0) & (labels == 1))\n","\n","    # Calculate the rates\n","    true_positive_rate = true_positive / (true_positive + false_negative)\n","    false_positive_rate = false_positive / (false_positive + true_negative)\n","    true_negative_rate = true_negative / (true_negative + false_positive)\n","    false_negative_rate = false_negative / (false_negative + true_positive)\n","\n","    return true_positive_rate, false_positive_rate, true_negative_rate, false_negative_rate"]},{"cell_type":"code","execution_count":null,"id":"f219ca01","metadata":{"id":"f219ca01"},"outputs":[],"source":["# multipliers = [1, 2, 4, 8]\n","# for multip in multipliers:\n","#   print('experiment with multiple:' + str(multip))\n","#   # loading data\n","#   X_pos = np.load(FOLDERNAME + '/partial_perfect_in_icsd.npy')\n","#   X_neg = np.load(FOLDERNAME + '/not_in_icsd_proofread.npy')\n","#   X_neg = X_neg[:10899*multip, :]\n","\n","#   #concatenate the features together and scale\n","#   X = np.concatenate((X_pos, X_neg), axis = 0)\n","#   std_scale=preprocessing.StandardScaler().fit(X)\n","#   X = std_scale.transform(X)\n","\n","#   #get output label\n","#   y = []\n","\n","#   y=get_labels(X_pos,X_neg)\n","\n","#     # Split the data into training and testing sets\n","#   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n","\n","#   model_kernel = KernelSVM(X_train, kernel='rbf')\n","#   opt_kernel = torch.optim.SGD(model_kernel.parameters(), lr=0.1)\n","\n","\n","#   # Check if GPU is available\n","#   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#   # Convert the data to PyTorch tensors and move them to the GPU\n","#   X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","#   y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n","#   X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n","#   y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n","\n","#   ##### Define the SVM model and kernel\n","\n","  \n","\n","\n","#   #######\n","  \n","\n","#   # Define the loss function\n","#   criterion = nn.BCEWithLogitsLoss()\n","\n","#   # Define the number of folds for cross-validation\n","#   num_folds = 5\n","\n","#   # Perform cross-validation\n","#   kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n","\n","#   # Initialize lists to store accuracy for each fold\n","#   fold_accuracies = []\n","\n","#   for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n","#       print(f\"Fold {fold+1}/{num_folds}\")\n","\n","#       # Split data into training and validation sets for the current fold\n","#       fold_X_train, fold_X_val = X_train[train_index], X_train[val_index]\n","#       fold_y_train, fold_y_val = y_train[train_index], y_train[val_index]\n","\n","#       # Create a TensorDataset and DataLoader for training\n","#       train_dataset = TensorDataset(fold_X_train, fold_y_train)\n","#       train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","\n","#       # Initialize the SVM model\n","#       svm = SVM()\n","\n","#       # Move the SVM model to GPU if available\n","#       device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#       svm.to(device)\n","#       model = svm\n","\n","#       # Evaluation on validation set\n","#       with torch.no_grad():\n","#           val_outputs = model(fold_X_val)\n","#           val_predictions = (val_outputs > 0.5).float().cpu().numpy()\n","          \n","#           true_positive_rate, false_positive_rate, true_negative_rate, false_negative_rate = calculate_classification_rates(val_predictions, fold_y_val.cpu().numpy())\n","#           print('true_positive_rate:' + str(true_positive_rate))\n","#           print('false_positive_rate:' + str(false_positive_rate))\n","#           print('true_negative_rate:' + str(true_negative_rate))\n","#           print('false_negative_rate:' + str(false_negative_rate))\n","          \n","#           fold_accuracy = accuracy_score(fold_y_val.cpu().numpy(), val_predictions)\n","#           fold_accuracies.append(fold_accuracy)\n","#           print(f\"Validation Accuracy: {fold_accuracy}\")\n","\n","#   # Calculate mean accuracy across all folds\n","#   mean_accuracy = sum(fold_accuracies) / num_folds\n","#   print(f\"Mean Cross-Validation Accuracy: {mean_accuracy}\")\n","\n","#   # Final evaluation on the test set\n","#   with torch.no_grad():\n","#       test_outputs = model(X_test)\n","#       test_predictions = (test_outputs > 0.5).float().cpu().numpy()\n","#       true_positive_rate, false_positive_rate, true_negative_rate, false_negative_rate = calculate_classification_rates(test_predictions, y_test.cpu().numpy())\n","#       print('true_positive_rate:' + str(true_positive_rate))\n","#       print('false_positive_rate:' + str(false_positive_rate))\n","#       print('true_negative_rate:' + str(true_negative_rate))\n","#       print('false_negative_rate:' + str(false_negative_rate))\n","#       test_accuracy = accuracy_score(y_test.cpu().numpy(), test_predictions)\n","#       print(f\"Test Accuracy: {test_accuracy}\")"]},{"cell_type":"code","source":["# Define MLP model\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(112, 64)\n","        self.fc2 = nn.Linear(64, 32)\n","        self.fc3 = nn.Linear(32, 2)\n","        self.act = nn.ELU()\n","\n","    def forward(self, x):\n","        x = self.act(self.fc1(x))\n","        x = self.act(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","multipliers = [1,4, 16, 64] #16, 32, 64, 128\n","test_accs = []\n","test_losses = []\n","for multip in multipliers:\n","  print('experiment with multiple:' + str(multip))\n","  ## loading data\n","  X_pos = np.load(FOLDERNAME + '/partial_perfect_in_icsd.npy')\n","  X_neg = np.load(FOLDERNAME + '/not_in_icsd_proofread.npy')\n","  X_neg = X_neg[:10899*multip, :]\n","\n","  #concatenate the features together and scale\n","  X = np.concatenate((X_pos, X_neg), axis = 0)\n","  std_scale=preprocessing.StandardScaler().fit(X)\n","  X = std_scale.transform(X)\n","\n","  #get output label\n","  y = []\n","\n","  y=get_labels(X_pos,X_neg)\n","\n","  # Split the data into training and testing sets\n","  X_da_train, X_test, y_da_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n","\n","  # Check if GPU is available\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","  # Convert the data to PyTorch tensors and move them to the GPU\n","  X_da_train = torch.tensor(X_da_train, dtype=torch.float32).to(device)\n","  y_da_train = torch.tensor(y_da_train, dtype=torch.float32).to(device)\n","  X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n","  y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n","  skf = StratifiedKFold(n_splits=5, shuffle=True)\n","\n","  # Hyperparameters\n","  batch_size = 32\n","  learning_rate = 0.001\n","  num_epochs = 10\n","\n","  # Lists to store losses and accuracies\n","  train_losses = []\n","  val_losses = []\n","  train_accs = []\n","  val_accs = []\n","\n","  # Perform k-fold cross-validation\n","  for train_index, val_index in skf.split(X_da_train.cpu().numpy(), y_da_train.cpu().numpy()):\n","      # Move the data back to CPU\n","      X_train, X_val = X_da_train[train_index].cpu(), X_da_train[val_index].cpu()\n","      y_train, y_val = y_da_train[train_index].cpu(), y_da_train[val_index].cpu()\n","\n","      # Convert data to PyTorch tensors and move to device\n","      X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","      y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","      X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","      y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n","\n","      # Create DataLoader for batch training\n","      train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n","      train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","      # Initialize model, loss function, and optimizer\n","      model = MLP().to(device)\n","      criterion = nn.CrossEntropyLoss()\n","      optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","      # Training loop\n","      for epoch in range(num_epochs):\n","          model.train()\n","          running_loss = 0.0\n","          correct = 0\n","          total = 0\n","\n","          for inputs, labels in train_loader:\n","              optimizer.zero_grad()\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","              loss.backward()\n","              optimizer.step()\n","\n","              running_loss += loss.item()\n","              _, predicted = torch.max(outputs.data, 1)\n","              total += labels.size(0)\n","              correct += (predicted == labels).sum().item()\n","\n","          # Compute training accuracy and loss\n","          train_acc = 100 * correct / total\n","          train_loss = running_loss / len(train_loader)\n","\n","          # Record training accuracy and loss\n","          train_accs.append(train_acc)\n","          train_losses.append(train_loss)\n","\n","          # Evaluation on validation set\n","          model.eval()\n","          with torch.no_grad():\n","            val_outputs = model(X_val)\n","            val_loss = criterion(val_outputs, y_val)\n","            _, val_predicted = torch.max(val_outputs.data, 1)\n","            val_acc = 100 * (val_predicted == y_val).sum().item() / y_val.size(0)\n","            # Record validation accuracy and loss\n","            val_accs.append(val_acc)\n","            val_losses.append(val_loss.item())\n","\n","            # Calculate confusion matrix\n","            val_true = y_val.cpu().numpy()\n","            val_pred = val_predicted.cpu().numpy()\n","            tn, fp, fn, tp = confusion_matrix(val_true, val_pred).ravel()\n","\n","            # Calculate rates\n","            val_tp_rate = tp / (tp + fn)\n","            val_tn_rate = tn / (tn + fp)\n","            val_fp_rate = fp / (fp + tn)\n","            val_fn_rate = fn / (fn + tp)\n","\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n","                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n","                  f\"Val Loss: {val_loss.item():.4f}, Val Acc: {val_acc:.2f}%\")\n","            print(f\"TP: {val_tp_rate}, \" f\"TN: {val_tn_rate}, \" f\"FP: {val_fp_rate}, \" f\"FN: {val_fn_rate}\")\n","  # Testing\n","  with torch.no_grad():\n","    test_outputs = model(X_test)\n","    y_test = y_test.long()\n","    test_loss = criterion(test_outputs, y_test)\n","    _, test_predicted = torch.max(test_outputs.data, 1)\n","    test_acc = 100 * (test_predicted == y_test).sum().item() / y_test.size(0)\n","    test_tp = ((test_predicted == 1) & (y_test == 1)).sum().item()\n","    test_tn = ((test_predicted == 0) & (y_test == 0)).sum().item()\n","    test_fp = ((test_predicted == 1) & (y_test == 0)).sum().item()\n","    test_fn = ((test_predicted == 0) & (y_test == 1)).sum().item()\n","    # Record testing accuracy and loss\n","    test_accs.append(test_acc)\n","    test_losses.append(test_loss.item())\n","\n","    print(f\"Testing - \"\n","          f\"Loss: {test_loss.item():.4f}, \"\n","          f\"Acc: {test_acc:.2f}%, \"\n","          f\"TP: {test_tp}, \"\n","          f\"TN: {test_tn}, \"\n","          f\"FP: {test_fp}, \"\n","          f\"FN: {test_fn}\")\n","    \n","    precision, recall, _ = precision_recall_curve(val_true, val_pred)\n","\n","    # Plot precision-recall curve\n","    plt.plot(recall, precision, label=f\"unlabel to label ratio {multip}:1\")\n","\n","# Plot random guessing line\n","plt.plot([0, 1], [0.5, 0.5], linestyle=\"--\", color=\"gray\", label=\"Random Guessing\")\n","\n","# Set plot properties\n","plt.xlabel(\"Recall\")\n","plt.ylabel(\"Precision\")\n","plt.title(\"Precision-Recall Curve\")\n","plt.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"PeBkA6VTsiRm","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1683820577007,"user_tz":420,"elapsed":1511653,"user":{"displayName":"William Cai","userId":"15768919470381419406"}},"outputId":"dcffd07f-7e33-4a78-bb01-029ad3eb20cb"},"id":"PeBkA6VTsiRm","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["experiment with multiple:1\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0741, Train Acc: 97.30%, Val Loss: 0.0096, Val Acc: 99.68%\n","TP: 0.9959677419354839, TN: 0.997716894977169, FP: 0.00228310502283105, FN: 0.004032258064516129\n","Epoch [2/10], Train Loss: 0.0148, Train Acc: 99.56%, Val Loss: 0.0067, Val Acc: 99.77%\n","TP: 0.9982718894009217, TN: 0.9971461187214612, FP: 0.0028538812785388126, FN: 0.0017281105990783411\n","Epoch [3/10], Train Loss: 0.0070, Train Acc: 99.78%, Val Loss: 0.0028, Val Acc: 99.89%\n","TP: 0.9988479262672811, TN: 0.9988584474885844, FP: 0.001141552511415525, FN: 0.001152073732718894\n","Epoch [4/10], Train Loss: 0.0059, Train Acc: 99.83%, Val Loss: 0.0116, Val Acc: 99.51%\n","TP: 0.9994239631336406, TN: 0.9908675799086758, FP: 0.0091324200913242, FN: 0.000576036866359447\n","Epoch [5/10], Train Loss: 0.0049, Train Acc: 99.81%, Val Loss: 0.0035, Val Acc: 99.89%\n","TP: 0.9982718894009217, TN: 0.9994292237442922, FP: 0.0005707762557077625, FN: 0.0017281105990783411\n","Epoch [6/10], Train Loss: 0.0062, Train Acc: 99.78%, Val Loss: 0.0023, Val Acc: 99.97%\n","TP: 0.9994239631336406, TN: 1.0, FP: 0.0, FN: 0.000576036866359447\n","Epoch [7/10], Train Loss: 0.0016, Train Acc: 99.96%, Val Loss: 0.0016, Val Acc: 99.91%\n","TP: 0.9988479262672811, TN: 0.9994292237442922, FP: 0.0005707762557077625, FN: 0.001152073732718894\n","Epoch [8/10], Train Loss: 0.0012, Train Acc: 99.99%, Val Loss: 0.0009, Val Acc: 99.97%\n","TP: 1.0, TN: 0.9994292237442922, FP: 0.0005707762557077625, FN: 0.0\n","Epoch [9/10], Train Loss: 0.0042, Train Acc: 99.85%, Val Loss: 0.0036, Val Acc: 99.91%\n","TP: 1.0, TN: 0.9982876712328768, FP: 0.0017123287671232876, FN: 0.0\n","Epoch [10/10], Train Loss: 0.0018, Train Acc: 99.95%, Val Loss: 0.0004, Val Acc: 100.00%\n","TP: 1.0, TN: 1.0, FP: 0.0, FN: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0706, Train Acc: 97.42%, Val Loss: 0.0261, Val Acc: 99.28%\n","TP: 0.9919354838709677, TN: 0.9937214611872146, FP: 0.006278538812785388, FN: 0.008064516129032258\n","Epoch [2/10], Train Loss: 0.0138, Train Acc: 99.61%, Val Loss: 0.0236, Val Acc: 99.28%\n","TP: 0.9953917050691244, TN: 0.990296803652968, FP: 0.009703196347031963, FN: 0.004608294930875576\n","Epoch [3/10], Train Loss: 0.0086, Train Acc: 99.73%, Val Loss: 0.0298, Val Acc: 99.20%\n","TP: 0.9844470046082949, TN: 0.9994292237442922, FP: 0.0005707762557077625, FN: 0.01555299539170507\n","Epoch [4/10], Train Loss: 0.0060, Train Acc: 99.84%, Val Loss: 0.0108, Val Acc: 99.89%\n","TP: 0.9976958525345622, TN: 1.0, FP: 0.0, FN: 0.002304147465437788\n","Epoch [5/10], Train Loss: 0.0027, Train Acc: 99.94%, Val Loss: 0.0117, Val Acc: 99.83%\n","TP: 0.9971198156682027, TN: 0.9994292237442922, FP: 0.0005707762557077625, FN: 0.002880184331797235\n","Epoch [6/10], Train Loss: 0.0025, Train Acc: 99.94%, Val Loss: 0.0197, Val Acc: 99.63%\n","TP: 0.9925115207373272, TN: 1.0, FP: 0.0, FN: 0.007488479262672811\n","Epoch [7/10], Train Loss: 0.0058, Train Acc: 99.84%, Val Loss: 0.0099, Val Acc: 99.97%\n","TP: 0.9994239631336406, TN: 1.0, FP: 0.0, FN: 0.000576036866359447\n","Epoch [8/10], Train Loss: 0.0032, Train Acc: 99.91%, Val Loss: 0.0096, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n","Epoch [9/10], Train Loss: 0.0022, Train Acc: 99.91%, Val Loss: 0.0083, Val Acc: 99.91%\n","TP: 0.9982718894009217, TN: 1.0, FP: 0.0, FN: 0.0017281105990783411\n","Epoch [10/10], Train Loss: 0.0026, Train Acc: 99.90%, Val Loss: 0.0301, Val Acc: 99.40%\n","TP: 0.9879032258064516, TN: 1.0, FP: 0.0, FN: 0.012096774193548387\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0749, Train Acc: 97.34%, Val Loss: 0.0261, Val Acc: 99.08%\n","TP: 0.9907887161773172, TN: 0.9908623643632211, FP: 0.009137635636778984, FN: 0.009211283822682787\n","Epoch [2/10], Train Loss: 0.0128, Train Acc: 99.73%, Val Loss: 0.0306, Val Acc: 99.11%\n","TP: 0.982153137593552, TN: 1.0, FP: 0.0, FN: 0.017846862406447898\n","Epoch [3/10], Train Loss: 0.0073, Train Acc: 99.80%, Val Loss: 0.0120, Val Acc: 99.51%\n","TP: 0.9953943580886586, TN: 0.9948600799543118, FP: 0.005139920045688178, FN: 0.004605641911341394\n","Epoch [4/10], Train Loss: 0.0057, Train Acc: 99.82%, Val Loss: 0.0050, Val Acc: 99.86%\n","TP: 0.9976971790443293, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.002302820955670697\n","Epoch [5/10], Train Loss: 0.0051, Train Acc: 99.84%, Val Loss: 0.0050, Val Acc: 99.91%\n","TP: 0.9988485895221646, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.0011514104778353484\n","Epoch [6/10], Train Loss: 0.0029, Train Acc: 99.89%, Val Loss: 0.0077, Val Acc: 99.80%\n","TP: 0.9994242947610823, TN: 0.9965733866362079, FP: 0.0034266133637921186, FN: 0.0005757052389176742\n","Epoch [7/10], Train Loss: 0.0016, Train Acc: 99.94%, Val Loss: 0.0042, Val Acc: 99.89%\n","TP: 0.998272884283247, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.0017271157167530224\n","Epoch [8/10], Train Loss: 0.0029, Train Acc: 99.89%, Val Loss: 0.0119, Val Acc: 99.77%\n","TP: 0.9953943580886586, TN: 1.0, FP: 0.0, FN: 0.004605641911341394\n","Epoch [9/10], Train Loss: 0.0029, Train Acc: 99.92%, Val Loss: 0.0101, Val Acc: 99.94%\n","TP: 0.9988485895221646, TN: 1.0, FP: 0.0, FN: 0.0011514104778353484\n","Epoch [10/10], Train Loss: 0.0003, Train Acc: 99.99%, Val Loss: 0.0133, Val Acc: 99.91%\n","TP: 0.998272884283247, TN: 1.0, FP: 0.0, FN: 0.0017271157167530224\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0728, Train Acc: 97.48%, Val Loss: 0.0142, Val Acc: 99.71%\n","TP: 0.9942396313364056, TN: 1.0, FP: 0.0, FN: 0.00576036866359447\n","Epoch [2/10], Train Loss: 0.0121, Train Acc: 99.69%, Val Loss: 0.0123, Val Acc: 99.57%\n","TP: 0.9976958525345622, TN: 0.9937178754997145, FP: 0.006282124500285551, FN: 0.002304147465437788\n","Epoch [3/10], Train Loss: 0.0070, Train Acc: 99.79%, Val Loss: 0.0043, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n","Epoch [4/10], Train Loss: 0.0054, Train Acc: 99.81%, Val Loss: 0.0038, Val Acc: 99.91%\n","TP: 0.9982718894009217, TN: 1.0, FP: 0.0, FN: 0.0017281105990783411\n","Epoch [5/10], Train Loss: 0.0058, Train Acc: 99.78%, Val Loss: 0.0021, Val Acc: 99.97%\n","TP: 0.9994239631336406, TN: 1.0, FP: 0.0, FN: 0.000576036866359447\n","Epoch [6/10], Train Loss: 0.0025, Train Acc: 99.91%, Val Loss: 0.0025, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n","Epoch [7/10], Train Loss: 0.0035, Train Acc: 99.89%, Val Loss: 0.0035, Val Acc: 99.91%\n","TP: 0.9982718894009217, TN: 1.0, FP: 0.0, FN: 0.0017281105990783411\n","Epoch [8/10], Train Loss: 0.0013, Train Acc: 99.98%, Val Loss: 0.0025, Val Acc: 99.97%\n","TP: 0.9994239631336406, TN: 1.0, FP: 0.0, FN: 0.000576036866359447\n","Epoch [9/10], Train Loss: 0.0052, Train Acc: 99.85%, Val Loss: 0.0028, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n","Epoch [10/10], Train Loss: 0.0009, Train Acc: 99.99%, Val Loss: 0.0022, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0730, Train Acc: 97.44%, Val Loss: 0.0134, Val Acc: 99.66%\n","TP: 0.9930875576036866, TN: 1.0, FP: 0.0, FN: 0.0069124423963133645\n","Epoch [2/10], Train Loss: 0.0126, Train Acc: 99.63%, Val Loss: 0.0060, Val Acc: 99.80%\n","TP: 0.9971198156682027, TN: 0.9988577955454027, FP: 0.001142204454597373, FN: 0.002880184331797235\n","Epoch [3/10], Train Loss: 0.0059, Train Acc: 99.84%, Val Loss: 0.0028, Val Acc: 99.89%\n","TP: 0.9976958525345622, TN: 1.0, FP: 0.0, FN: 0.002304147465437788\n","Epoch [4/10], Train Loss: 0.0066, Train Acc: 99.79%, Val Loss: 0.0035, Val Acc: 99.83%\n","TP: 0.9965437788018433, TN: 1.0, FP: 0.0, FN: 0.0034562211981566822\n","Epoch [5/10], Train Loss: 0.0038, Train Acc: 99.87%, Val Loss: 0.0075, Val Acc: 99.77%\n","TP: 0.9953917050691244, TN: 1.0, FP: 0.0, FN: 0.004608294930875576\n","Epoch [6/10], Train Loss: 0.0039, Train Acc: 99.86%, Val Loss: 0.0060, Val Acc: 99.77%\n","TP: 0.9982718894009217, TN: 0.9971444888635066, FP: 0.0028555111364934323, FN: 0.0017281105990783411\n","Epoch [7/10], Train Loss: 0.0021, Train Acc: 99.92%, Val Loss: 0.0017, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n","Epoch [8/10], Train Loss: 0.0018, Train Acc: 99.96%, Val Loss: 0.0033, Val Acc: 99.91%\n","TP: 0.9988479262672811, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.001152073732718894\n","Epoch [9/10], Train Loss: 0.0031, Train Acc: 99.89%, Val Loss: 0.0087, Val Acc: 99.80%\n","TP: 0.9965437788018433, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.0034562211981566822\n","Epoch [10/10], Train Loss: 0.0032, Train Acc: 99.90%, Val Loss: 0.0032, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n","Testing - Loss: 0.0085, Acc: 99.77%, TP: 2209, TN: 2141, FP: 1, FN: 9\n","experiment with multiple:4\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0274, Train Acc: 99.21%, Val Loss: 0.0045, Val Acc: 99.91%\n","TP: 0.9960159362549801, TN: 0.9998563837426396, FP: 0.0001436162573603332, FN: 0.00398406374501992\n","Epoch [2/10], Train Loss: 0.0047, Train Acc: 99.87%, Val Loss: 0.0049, Val Acc: 99.81%\n","TP: 0.9988616960728515, TN: 0.997845756139595, FP: 0.002154243860404998, FN: 0.0011383039271485487\n","Epoch [3/10], Train Loss: 0.0028, Train Acc: 99.91%, Val Loss: 0.0122, Val Acc: 99.63%\n","TP: 0.983494593056346, TN: 0.999569151227919, FP: 0.00043084877208099956, FN: 0.016505406943653957\n","Epoch [4/10], Train Loss: 0.0028, Train Acc: 99.94%, Val Loss: 0.0027, Val Acc: 99.93%\n","TP: 0.9965850882185544, TN: 1.0, FP: 0.0, FN: 0.003414911781445646\n","Epoch [5/10], Train Loss: 0.0021, Train Acc: 99.94%, Val Loss: 0.0017, Val Acc: 99.95%\n","TP: 0.9977233921457029, TN: 1.0, FP: 0.0, FN: 0.0022766078542970974\n","Epoch [6/10], Train Loss: 0.0024, Train Acc: 99.92%, Val Loss: 0.0043, Val Acc: 99.87%\n","TP: 0.9977233921457029, TN: 0.9989946861984776, FP: 0.0010053138015223323, FN: 0.0022766078542970974\n","Epoch [7/10], Train Loss: 0.0019, Train Acc: 99.96%, Val Loss: 0.0016, Val Acc: 99.99%\n","TP: 0.9994308480364257, TN: 1.0, FP: 0.0, FN: 0.0005691519635742744\n","Epoch [8/10], Train Loss: 0.0015, Train Acc: 99.95%, Val Loss: 0.0052, Val Acc: 99.90%\n","TP: 0.9948776323278316, TN: 1.0, FP: 0.0, FN: 0.005122367672168469\n","Epoch [9/10], Train Loss: 0.0017, Train Acc: 99.95%, Val Loss: 0.0011, Val Acc: 99.98%\n","TP: 0.9988616960728515, TN: 1.0, FP: 0.0, FN: 0.0011383039271485487\n","Epoch [10/10], Train Loss: 0.0025, Train Acc: 99.93%, Val Loss: 0.0019, Val Acc: 99.97%\n","TP: 0.9982925441092771, TN: 1.0, FP: 0.0, FN: 0.001707455890722823\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0304, Train Acc: 98.85%, Val Loss: 0.0039, Val Acc: 99.93%\n","TP: 0.9965831435079726, TN: 1.0, FP: 0.0, FN: 0.003416856492027335\n","Epoch [2/10], Train Loss: 0.0058, Train Acc: 99.82%, Val Loss: 0.0052, Val Acc: 99.90%\n","TP: 0.9977220956719818, TN: 0.9992819187131984, FP: 0.0007180812868016659, FN: 0.002277904328018223\n","Epoch [3/10], Train Loss: 0.0032, Train Acc: 99.92%, Val Loss: 0.0065, Val Acc: 99.87%\n","TP: 0.9937357630979499, TN: 1.0, FP: 0.0, FN: 0.006264236902050114\n","Epoch [4/10], Train Loss: 0.0030, Train Acc: 99.90%, Val Loss: 0.0033, Val Acc: 99.94%\n","TP: 0.9971526195899773, TN: 1.0, FP: 0.0, FN: 0.0028473804100227792\n","Epoch [5/10], Train Loss: 0.0019, Train Acc: 99.95%, Val Loss: 0.0030, Val Acc: 99.97%\n","TP: 0.9982915717539863, TN: 1.0, FP: 0.0, FN: 0.0017084282460136675\n","Epoch [6/10], Train Loss: 0.0016, Train Acc: 99.95%, Val Loss: 0.0028, Val Acc: 99.97%\n","TP: 0.9982915717539863, TN: 1.0, FP: 0.0, FN: 0.0017084282460136675\n","Epoch [7/10], Train Loss: 0.0012, Train Acc: 99.97%, Val Loss: 0.0035, Val Acc: 99.92%\n","TP: 0.9982915717539863, TN: 0.9994255349705586, FP: 0.0005744650294413328, FN: 0.0017084282460136675\n","Epoch [8/10], Train Loss: 0.0018, Train Acc: 99.95%, Val Loss: 0.0028, Val Acc: 99.97%\n","TP: 0.9982915717539863, TN: 1.0, FP: 0.0, FN: 0.0017084282460136675\n","Epoch [9/10], Train Loss: 0.0016, Train Acc: 99.95%, Val Loss: 0.0051, Val Acc: 99.93%\n","TP: 0.9965831435079726, TN: 1.0, FP: 0.0, FN: 0.003416856492027335\n","Epoch [10/10], Train Loss: 0.0005, Train Acc: 99.99%, Val Loss: 0.0033, Val Acc: 99.95%\n","TP: 0.9977220956719818, TN: 1.0, FP: 0.0, FN: 0.002277904328018223\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0323, Train Acc: 98.89%, Val Loss: 0.0081, Val Acc: 99.75%\n","TP: 0.9874715261958997, TN: 1.0, FP: 0.0, FN: 0.012528473804100227\n","Epoch [2/10], Train Loss: 0.0061, Train Acc: 99.83%, Val Loss: 0.0033, Val Acc: 99.94%\n","TP: 0.9971526195899773, TN: 1.0, FP: 0.0, FN: 0.0028473804100227792\n","Epoch [3/10], Train Loss: 0.0043, Train Acc: 99.86%, Val Loss: 0.0017, Val Acc: 99.92%\n","TP: 0.9960136674259681, TN: 1.0, FP: 0.0, FN: 0.003986332574031891\n","Epoch [4/10], Train Loss: 0.0026, Train Acc: 99.92%, Val Loss: 0.0014, Val Acc: 99.95%\n","TP: 0.9977220956719818, TN: 1.0, FP: 0.0, FN: 0.002277904328018223\n","Epoch [5/10], Train Loss: 0.0043, Train Acc: 99.89%, Val Loss: 0.0036, Val Acc: 99.90%\n","TP: 0.9971526195899773, TN: 0.9994255349705586, FP: 0.0005744650294413328, FN: 0.0028473804100227792\n","Epoch [6/10], Train Loss: 0.0022, Train Acc: 99.93%, Val Loss: 0.0008, Val Acc: 99.95%\n","TP: 0.9977220956719818, TN: 1.0, FP: 0.0, FN: 0.002277904328018223\n","Epoch [7/10], Train Loss: 0.0016, Train Acc: 99.95%, Val Loss: 0.0003, Val Acc: 99.99%\n","TP: 0.9994305239179955, TN: 1.0, FP: 0.0, FN: 0.0005694760820045558\n","Epoch [8/10], Train Loss: 0.0011, Train Acc: 99.96%, Val Loss: 0.0001, Val Acc: 100.00%\n","TP: 1.0, TN: 1.0, FP: 0.0, FN: 0.0\n","Epoch [9/10], Train Loss: 0.0016, Train Acc: 99.94%, Val Loss: 0.0010, Val Acc: 99.98%\n","TP: 0.9988610478359908, TN: 1.0, FP: 0.0, FN: 0.0011389521640091116\n","Epoch [10/10], Train Loss: 0.0024, Train Acc: 99.95%, Val Loss: 0.0003, Val Acc: 99.99%\n","TP: 0.9994305239179955, TN: 1.0, FP: 0.0, FN: 0.0005694760820045558\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0283, Train Acc: 99.10%, Val Loss: 0.0337, Val Acc: 99.06%\n","TP: 0.9533029612756264, TN: 1.0, FP: 0.0, FN: 0.04669703872437358\n","Epoch [2/10], Train Loss: 0.0057, Train Acc: 99.85%, Val Loss: 0.0027, Val Acc: 99.91%\n","TP: 0.9954441913439636, TN: 1.0, FP: 0.0, FN: 0.004555808656036446\n","Epoch [3/10], Train Loss: 0.0032, Train Acc: 99.91%, Val Loss: 0.0018, Val Acc: 99.93%\n","TP: 0.9965831435079726, TN: 1.0, FP: 0.0, FN: 0.003416856492027335\n","Epoch [4/10], Train Loss: 0.0039, Train Acc: 99.88%, Val Loss: 0.0019, Val Acc: 99.98%\n","TP: 0.9988610478359908, TN: 1.0, FP: 0.0, FN: 0.0011389521640091116\n","Epoch [5/10], Train Loss: 0.0016, Train Acc: 99.96%, Val Loss: 0.0019, Val Acc: 99.91%\n","TP: 0.9954441913439636, TN: 1.0, FP: 0.0, FN: 0.004555808656036446\n","Epoch [6/10], Train Loss: 0.0019, Train Acc: 99.94%, Val Loss: 0.0057, Val Acc: 99.82%\n","TP: 1.0, TN: 0.9977021398822347, FP: 0.002297860117765331, FN: 0.0\n","Epoch [7/10], Train Loss: 0.0029, Train Acc: 99.91%, Val Loss: 0.0018, Val Acc: 99.95%\n","TP: 0.9977220956719818, TN: 1.0, FP: 0.0, FN: 0.002277904328018223\n","Epoch [8/10], Train Loss: 0.0013, Train Acc: 99.95%, Val Loss: 0.0004, Val Acc: 99.98%\n","TP: 0.9988610478359908, TN: 1.0, FP: 0.0, FN: 0.0011389521640091116\n","Epoch [9/10], Train Loss: 0.0012, Train Acc: 99.97%, Val Loss: 0.0004, Val Acc: 99.99%\n","TP: 0.9994305239179955, TN: 1.0, FP: 0.0, FN: 0.0005694760820045558\n","Epoch [10/10], Train Loss: 0.0020, Train Acc: 99.95%, Val Loss: 0.0004, Val Acc: 99.99%\n","TP: 1.0, TN: 0.9998563837426396, FP: 0.0001436162573603332, FN: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0299, Train Acc: 99.01%, Val Loss: 0.0059, Val Acc: 99.85%\n","TP: 0.9931701764371087, TN: 0.9998563631140477, FP: 0.00014363688595231256, FN: 0.006829823562891292\n","Epoch [2/10], Train Loss: 0.0055, Train Acc: 99.85%, Val Loss: 0.0048, Val Acc: 99.91%\n","TP: 0.9960159362549801, TN: 0.9998563631140477, FP: 0.00014363688595231256, FN: 0.00398406374501992\n","Epoch [3/10], Train Loss: 0.0039, Train Acc: 99.90%, Val Loss: 0.0039, Val Acc: 99.92%\n","TP: 0.9960159362549801, TN: 1.0, FP: 0.0, FN: 0.00398406374501992\n","Epoch [4/10], Train Loss: 0.0027, Train Acc: 99.93%, Val Loss: 0.0032, Val Acc: 99.92%\n","TP: 0.9960159362549801, TN: 1.0, FP: 0.0, FN: 0.00398406374501992\n","Epoch [5/10], Train Loss: 0.0037, Train Acc: 99.87%, Val Loss: 0.0039, Val Acc: 99.92%\n","TP: 0.9960159362549801, TN: 1.0, FP: 0.0, FN: 0.00398406374501992\n","Epoch [6/10], Train Loss: 0.0016, Train Acc: 99.95%, Val Loss: 0.0020, Val Acc: 99.93%\n","TP: 0.9965850882185544, TN: 1.0, FP: 0.0, FN: 0.003414911781445646\n","Epoch [7/10], Train Loss: 0.0015, Train Acc: 99.94%, Val Loss: 0.0097, Val Acc: 99.71%\n","TP: 0.9982925441092771, TN: 0.9968399885090491, FP: 0.003160011490950876, FN: 0.001707455890722823\n","Epoch [8/10], Train Loss: 0.0018, Train Acc: 99.93%, Val Loss: 0.0045, Val Acc: 99.81%\n","TP: 0.9977233921457029, TN: 0.9981327204826199, FP: 0.0018672795173800632, FN: 0.0022766078542970974\n","Epoch [9/10], Train Loss: 0.0020, Train Acc: 99.95%, Val Loss: 0.0042, Val Acc: 99.89%\n","TP: 0.9977233921457029, TN: 0.9991381786842861, FP: 0.0008618213157138753, FN: 0.0022766078542970974\n","Epoch [10/10], Train Loss: 0.0008, Train Acc: 99.98%, Val Loss: 0.0016, Val Acc: 99.95%\n","TP: 0.9977233921457029, TN: 1.0, FP: 0.0, FN: 0.0022766078542970974\n","Testing - Loss: 0.0011, Acc: 99.96%, TP: 2113, TN: 8782, FP: 0, FN: 4\n","experiment with multiple:16\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0922, Train Acc: 97.07%, Val Loss: 0.0670, Val Acc: 97.91%\n","TP: 0.7611174458380844, TN: 0.9927936325828195, FP: 0.007206367417180554, FN: 0.23888255416191562\n","Epoch [2/10], Train Loss: 0.0597, Train Acc: 98.07%, Val Loss: 0.0677, Val Acc: 97.71%\n","TP: 0.8010262257696693, TN: 0.9881686505091065, FP: 0.011831349490893445, FN: 0.19897377423033066\n","Epoch [3/10], Train Loss: 0.0500, Train Acc: 98.42%, Val Loss: 0.0505, Val Acc: 98.42%\n","TP: 0.758266818700114, TN: 0.9983866341603327, FP: 0.001613365839667288, FN: 0.24173318129988597\n","Epoch [4/10], Train Loss: 0.0454, Train Acc: 98.54%, Val Loss: 0.0458, Val Acc: 98.63%\n","TP: 0.8175598631698974, TN: 0.99688082604331, FP: 0.0031191739566900903, FN: 0.18244013683010263\n","Epoch [5/10], Train Loss: 0.0409, Train Acc: 98.71%, Val Loss: 0.0439, Val Acc: 98.71%\n","TP: 0.8329532497149373, TN: 0.9967732683206654, FP: 0.003226731679334576, FN: 0.16704675028506272\n","Epoch [6/10], Train Loss: 0.0375, Train Acc: 98.80%, Val Loss: 0.0441, Val Acc: 98.69%\n","TP: 0.8118586088939567, TN: 0.9979564032697548, FP: 0.0020435967302452314, FN: 0.18814139110604333\n","Epoch [7/10], Train Loss: 0.0353, Train Acc: 98.91%, Val Loss: 0.0381, Val Acc: 98.87%\n","TP: 0.8318129988597491, TN: 0.9985658970314069, FP: 0.001434102968593145, FN: 0.16818700114025084\n","Epoch [8/10], Train Loss: 0.0331, Train Acc: 98.97%, Val Loss: 0.0382, Val Acc: 98.89%\n","TP: 0.8540478905359179, TN: 0.9974186146565324, FP: 0.002581385343467661, FN: 0.1459521094640821\n","Epoch [9/10], Train Loss: 0.0317, Train Acc: 99.02%, Val Loss: 0.0374, Val Acc: 98.90%\n","TP: 0.8563283922462942, TN: 0.9973110569338879, FP: 0.0026889430661121466, FN: 0.14367160775370583\n","Epoch [10/10], Train Loss: 0.0299, Train Acc: 99.07%, Val Loss: 0.0369, Val Acc: 98.94%\n","TP: 0.8597491448118586, TN: 0.9975620249533916, FP: 0.0024379750466083463, FN: 0.1402508551881414\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0925, Train Acc: 96.97%, Val Loss: 0.0723, Val Acc: 97.61%\n","TP: 0.6322690992018244, TN: 0.9977053529812484, FP: 0.002294647018751569, FN: 0.3677309007981756\n","Epoch [2/10], Train Loss: 0.0601, Train Acc: 98.05%, Val Loss: 0.0548, Val Acc: 98.33%\n","TP: 0.8015963511972634, TN: 0.994693628769137, FP: 0.005306371230863002, FN: 0.19840364880273662\n","Epoch [3/10], Train Loss: 0.0501, Train Acc: 98.41%, Val Loss: 0.0495, Val Acc: 98.51%\n","TP: 0.8084378563283923, TN: 0.9962353447348608, FP: 0.003764655265139292, FN: 0.19156214367160776\n","Epoch [4/10], Train Loss: 0.0446, Train Acc: 98.57%, Val Loss: 0.0483, Val Acc: 98.55%\n","TP: 0.8124287343215507, TN: 0.9963429063138647, FP: 0.0036570936861353123, FN: 0.18757126567844926\n","Epoch [5/10], Train Loss: 0.0411, Train Acc: 98.70%, Val Loss: 0.0453, Val Acc: 98.56%\n","TP: 0.830672748004561, TN: 0.9953031443834929, FP: 0.004696855616507117, FN: 0.169327251995439\n","Epoch [6/10], Train Loss: 0.0382, Train Acc: 98.81%, Val Loss: 0.0405, Val Acc: 98.87%\n","TP: 0.8278221208665907, TN: 0.9987809687712882, FP: 0.0012190312287117709, FN: 0.17217787913340935\n","Epoch [7/10], Train Loss: 0.0360, Train Acc: 98.90%, Val Loss: 0.0410, Val Acc: 98.83%\n","TP: 0.8181299885974914, TN: 0.9989602380696282, FP: 0.0010397619303718045, FN: 0.18187001140250855\n","Epoch [8/10], Train Loss: 0.0340, Train Acc: 98.96%, Val Loss: 0.0407, Val Acc: 98.79%\n","TP: 0.8409350057012542, TN: 0.9970958373668926, FP: 0.002904162633107454, FN: 0.15906499429874574\n","Epoch [9/10], Train Loss: 0.0327, Train Acc: 99.01%, Val Loss: 0.0370, Val Acc: 98.96%\n","TP: 0.8335233751425314, TN: 0.9994621921049801, FP: 0.0005378078950198989, FN: 0.16647662485746864\n","Epoch [10/10], Train Loss: 0.0305, Train Acc: 99.07%, Val Loss: 0.0330, Val Acc: 99.11%\n","TP: 0.8677309007981756, TN: 0.9988885303502922, FP: 0.001111469649707791, FN: 0.1322690992018244\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0932, Train Acc: 96.94%, Val Loss: 0.0702, Val Acc: 97.71%\n","TP: 0.750285062713797, TN: 0.9913592198200136, FP: 0.008640780179986375, FN: 0.24971493728620298\n","Epoch [2/10], Train Loss: 0.0601, Train Acc: 98.11%, Val Loss: 0.0522, Val Acc: 98.24%\n","TP: 0.7548460661345496, TN: 0.9967014449105446, FP: 0.00329855508945538, FN: 0.2451539338654504\n","Epoch [3/10], Train Loss: 0.0511, Train Acc: 98.39%, Val Loss: 0.0480, Val Acc: 98.44%\n","TP: 0.7799315849486887, TN: 0.9973109605249005, FP: 0.0026890394750994943, FN: 0.22006841505131128\n","Epoch [4/10], Train Loss: 0.0450, Train Acc: 98.57%, Val Loss: 0.0499, Val Acc: 98.34%\n","TP: 0.8215507411630558, TN: 0.9935463052597612, FP: 0.006453694740238786, FN: 0.17844925883694412\n","Epoch [5/10], Train Loss: 0.0409, Train Acc: 98.72%, Val Loss: 0.0413, Val Acc: 98.73%\n","TP: 0.8403648802736602, TN: 0.9965580294718727, FP: 0.003441970528127353, FN: 0.15963511972633979\n","Epoch [6/10], Train Loss: 0.0376, Train Acc: 98.84%, Val Loss: 0.0403, Val Acc: 98.69%\n","TP: 0.8392246294184721, TN: 0.9962353447348608, FP: 0.003764655265139292, FN: 0.16077537058152794\n","Epoch [7/10], Train Loss: 0.0354, Train Acc: 98.89%, Val Loss: 0.0406, Val Acc: 98.75%\n","TP: 0.8454960091220068, TN: 0.9964146140332006, FP: 0.003585385966799326, FN: 0.15450399087799316\n","Epoch [8/10], Train Loss: 0.0338, Train Acc: 98.94%, Val Loss: 0.0366, Val Acc: 98.82%\n","TP: 0.8568985176738882, TN: 0.9964146140332006, FP: 0.003585385966799326, FN: 0.14310148232611175\n","Epoch [9/10], Train Loss: 0.0316, Train Acc: 99.01%, Val Loss: 0.0371, Val Acc: 98.91%\n","TP: 0.863169897377423, TN: 0.9969882757878885, FP: 0.003011724212111434, FN: 0.13683010262257697\n","Epoch [10/10], Train Loss: 0.0301, Train Acc: 99.07%, Val Loss: 0.0324, Val Acc: 99.02%\n","TP: 0.8814139110604333, TN: 0.9969882757878885, FP: 0.003011724212111434, FN: 0.11858608893956671\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0944, Train Acc: 97.00%, Val Loss: 0.0675, Val Acc: 97.72%\n","TP: 0.6812998859749145, TN: 0.9957692445591768, FP: 0.0042307554408232044, FN: 0.3187001140250855\n","Epoch [2/10], Train Loss: 0.0614, Train Acc: 98.01%, Val Loss: 0.0525, Val Acc: 98.33%\n","TP: 0.7645381984036488, TN: 0.9970958373668926, FP: 0.002904162633107454, FN: 0.2354618015963512\n","Epoch [3/10], Train Loss: 0.0517, Train Acc: 98.35%, Val Loss: 0.0458, Val Acc: 98.45%\n","TP: 0.7622576966932725, TN: 0.9984941378939443, FP: 0.001505862106055717, FN: 0.2377423033067275\n","Epoch [4/10], Train Loss: 0.0459, Train Acc: 98.57%, Val Loss: 0.0467, Val Acc: 98.52%\n","TP: 0.7827822120866591, TN: 0.9978846222795884, FP: 0.0021153777204116022, FN: 0.21721778791334093\n","Epoch [5/10], Train Loss: 0.0419, Train Acc: 98.69%, Val Loss: 0.0440, Val Acc: 98.59%\n","TP: 0.8472063854047891, TN: 0.994657774909469, FP: 0.005342225090530996, FN: 0.15279361459521096\n","Epoch [6/10], Train Loss: 0.0387, Train Acc: 98.81%, Val Loss: 0.0527, Val Acc: 98.39%\n","TP: 0.8825541619156214, TN: 0.9902836040299738, FP: 0.009716395970026173, FN: 0.11744583808437856\n","Epoch [7/10], Train Loss: 0.0364, Train Acc: 98.88%, Val Loss: 0.0326, Val Acc: 98.99%\n","TP: 0.8449258836944128, TN: 0.9989960919292962, FP: 0.0010039080707038113, FN: 0.15507411630558723\n","Epoch [8/10], Train Loss: 0.0340, Train Acc: 98.94%, Val Loss: 0.0340, Val Acc: 98.94%\n","TP: 0.8460661345496009, TN: 0.9984224301746083, FP: 0.0015775698253917034, FN: 0.15393386545039908\n","Epoch [9/10], Train Loss: 0.0321, Train Acc: 99.01%, Val Loss: 0.0301, Val Acc: 99.08%\n","TP: 0.8563283922462942, TN: 0.9992470689469721, FP: 0.0007529310530278584, FN: 0.14367160775370583\n","Epoch [10/10], Train Loss: 0.0309, Train Acc: 99.05%, Val Loss: 0.0328, Val Acc: 98.94%\n","TP: 0.855188141391106, TN: 0.9978129145602525, FP: 0.0021870854397475887, FN: 0.14481185860889395\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0936, Train Acc: 96.92%, Val Loss: 0.0685, Val Acc: 97.86%\n","TP: 0.6944127708095781, TN: 0.9964504678928686, FP: 0.0035495321071313327, FN: 0.3055872291904219\n","Epoch [2/10], Train Loss: 0.0611, Train Acc: 98.05%, Val Loss: 0.0542, Val Acc: 98.42%\n","TP: 0.7867730900798175, TN: 0.9966297371912086, FP: 0.0033702628087913665, FN: 0.21322690992018245\n","Epoch [3/10], Train Loss: 0.0509, Train Acc: 98.39%, Val Loss: 0.0512, Val Acc: 98.35%\n","TP: 0.7953249714937286, TN: 0.9953389982431609, FP: 0.004661001756839124, FN: 0.20467502850627137\n","Epoch [4/10], Train Loss: 0.0448, Train Acc: 98.58%, Val Loss: 0.0426, Val Acc: 98.64%\n","TP: 0.8038768529076397, TN: 0.9979204761392564, FP: 0.002079523860743609, FN: 0.1961231470923603\n","Epoch [5/10], Train Loss: 0.0419, Train Acc: 98.69%, Val Loss: 0.0410, Val Acc: 98.76%\n","TP: 0.8289623717217788, TN: 0.9975260836829085, FP: 0.002473916317091535, FN: 0.17103762827822122\n","Epoch [6/10], Train Loss: 0.0382, Train Acc: 98.82%, Val Loss: 0.0372, Val Acc: 98.79%\n","TP: 0.8346636259977195, TN: 0.9975619375425765, FP: 0.0024380624574235417, FN: 0.1653363740022805\n","Epoch [7/10], Train Loss: 0.0363, Train Acc: 98.88%, Val Loss: 0.0370, Val Acc: 98.90%\n","TP: 0.8717217787913341, TN: 0.9963787601735327, FP: 0.003621239826467319, FN: 0.12827822120866592\n","Epoch [8/10], Train Loss: 0.0340, Train Acc: 98.97%, Val Loss: 0.0349, Val Acc: 98.92%\n","TP: 0.8563283922462942, TN: 0.9975977914022445, FP: 0.0024022085977555485, FN: 0.14367160775370583\n","Epoch [9/10], Train Loss: 0.0324, Train Acc: 98.99%, Val Loss: 0.0326, Val Acc: 98.97%\n","TP: 0.8580387685290763, TN: 0.9980280377182603, FP: 0.0019719622817396293, FN: 0.1419612314709236\n","Epoch [10/10], Train Loss: 0.0310, Train Acc: 99.04%, Val Loss: 0.0339, Val Acc: 98.94%\n","TP: 0.8848346636259977, TN: 0.9960202215768528, FP: 0.003979778423147251, FN: 0.11516533637400228\n","Testing - Loss: 0.0340, Acc: 98.95%, TP: 1876, TN: 34792, FP: 136, FN: 253\n","experiment with multiple:64\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0527, Train Acc: 98.58%, Val Loss: 0.0458, Val Acc: 98.71%\n","TP: 0.19862227324913892, TN: 0.9994534441975486, FP: 0.0005465558024514372, FN: 0.801377726750861\n","Epoch [2/10], Train Loss: 0.0423, Train Acc: 98.81%, Val Loss: 0.0406, Val Acc: 98.84%\n","TP: 0.3742824339839265, TN: 0.9979481757580102, FP: 0.0020518242419898217, FN: 0.6257175660160735\n","Epoch [3/10], Train Loss: 0.0382, Train Acc: 98.90%, Val Loss: 0.0420, Val Acc: 98.70%\n","TP: 0.4730195177956372, TN: 0.9950361981219984, FP: 0.004963801878001577, FN: 0.5269804822043628\n","Epoch [4/10], Train Loss: 0.0358, Train Acc: 98.97%, Val Loss: 0.0366, Val Acc: 98.90%\n","TP: 0.45120551090700345, TN: 0.9974105798867464, FP: 0.00258942011325353, FN: 0.5487944890929966\n","Epoch [5/10], Train Loss: 0.0336, Train Acc: 99.02%, Val Loss: 0.0357, Val Acc: 99.01%\n","TP: 0.3714121699196326, TN: 0.9997222421331804, FP: 0.0002777578668195828, FN: 0.6285878300803674\n","Epoch [6/10], Train Loss: 0.0322, Train Acc: 99.06%, Val Loss: 0.0333, Val Acc: 99.02%\n","TP: 0.40470723306544204, TN: 0.9993638448856713, FP: 0.000636155114328722, FN: 0.595292766934558\n","Epoch [7/10], Train Loss: 0.0309, Train Acc: 99.10%, Val Loss: 0.0332, Val Acc: 99.06%\n","TP: 0.5103329506314581, TN: 0.9981452942441402, FP: 0.001854705755859795, FN: 0.4896670493685419\n","Epoch [8/10], Train Loss: 0.0298, Train Acc: 99.13%, Val Loss: 0.0305, Val Acc: 99.14%\n","TP: 0.5321469575200919, TN: 0.9986112106659021, FP: 0.0013887893340979141, FN: 0.46785304247990817\n","Epoch [9/10], Train Loss: 0.0288, Train Acc: 99.15%, Val Loss: 0.0329, Val Acc: 99.08%\n","TP: 0.4592422502870264, TN: 0.9991040068812271, FP: 0.0008959931187728479, FN: 0.5407577497129736\n","Epoch [10/10], Train Loss: 0.0281, Train Acc: 99.18%, Val Loss: 0.0303, Val Acc: 99.13%\n","TP: 0.4896670493685419, TN: 0.9991577664683535, FP: 0.0008422335316464769, FN: 0.5103329506314581\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0521, Train Acc: 98.61%, Val Loss: 0.0435, Val Acc: 98.80%\n","TP: 0.30539609644087257, TN: 0.9986291305282775, FP: 0.0013708694717224571, FN: 0.6946039035591275\n","Epoch [2/10], Train Loss: 0.0422, Train Acc: 98.80%, Val Loss: 0.0409, Val Acc: 98.87%\n","TP: 0.29793340987370837, TN: 0.9994444842663608, FP: 0.0005555157336391656, FN: 0.7020665901262916\n","Epoch [3/10], Train Loss: 0.0380, Train Acc: 98.90%, Val Loss: 0.0380, Val Acc: 98.91%\n","TP: 0.35648679678530426, TN: 0.9989964877069744, FP: 0.0010035122930255895, FN: 0.6435132032146957\n","Epoch [4/10], Train Loss: 0.0355, Train Acc: 98.97%, Val Loss: 0.0354, Val Acc: 99.02%\n","TP: 0.3920780711825488, TN: 0.9995340835782381, FP: 0.0004659164217618809, FN: 0.6079219288174512\n","Epoch [5/10], Train Loss: 0.0335, Train Acc: 99.01%, Val Loss: 0.0348, Val Acc: 99.02%\n","TP: 0.4506314580941447, TN: 0.9986560103218407, FP: 0.0013439896781592717, FN: 0.5493685419058554\n","Epoch [6/10], Train Loss: 0.0321, Train Acc: 99.05%, Val Loss: 0.0330, Val Acc: 99.07%\n","TP: 0.5223880597014925, TN: 0.9979929754139488, FP: 0.002007024586051179, FN: 0.47761194029850745\n","Epoch [7/10], Train Loss: 0.0308, Train Acc: 99.09%, Val Loss: 0.0326, Val Acc: 99.09%\n","TP: 0.5120551090700345, TN: 0.9983782524550211, FP: 0.0016217475449788546, FN: 0.48794489092996557\n","Epoch [8/10], Train Loss: 0.0298, Train Acc: 99.11%, Val Loss: 0.0316, Val Acc: 99.09%\n","TP: 0.4890929965556831, TN: 0.9987456096337181, FP: 0.001254390366281987, FN: 0.5109070034443168\n","Epoch [9/10], Train Loss: 0.0290, Train Acc: 99.14%, Val Loss: 0.0309, Val Acc: 99.12%\n","TP: 0.5045924225028703, TN: 0.9988262490144075, FP: 0.0011737509855924307, FN: 0.4954075774971297\n","Epoch [10/10], Train Loss: 0.0282, Train Acc: 99.16%, Val Loss: 0.0313, Val Acc: 99.11%\n","TP: 0.5177956371986223, TN: 0.9984947315604616, FP: 0.0015052684395383843, FN: 0.48220436280137774\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0522, Train Acc: 98.61%, Val Loss: 0.0461, Val Acc: 98.73%\n","TP: 0.21182548794489092, TN: 0.9994534441975486, FP: 0.0005465558024514372, FN: 0.788174512055109\n","Epoch [2/10], Train Loss: 0.0419, Train Acc: 98.81%, Val Loss: 0.0409, Val Acc: 98.84%\n","TP: 0.34615384615384615, TN: 0.9983782524550211, FP: 0.0016217475449788546, FN: 0.6538461538461539\n","Epoch [3/10], Train Loss: 0.0380, Train Acc: 98.91%, Val Loss: 0.0375, Val Acc: 98.93%\n","TP: 0.38461538461538464, TN: 0.9987635294960935, FP: 0.00123647050390653, FN: 0.6153846153846154\n","Epoch [4/10], Train Loss: 0.0353, Train Acc: 98.98%, Val Loss: 0.0371, Val Acc: 98.94%\n","TP: 0.3742824339839265, TN: 0.9990412873629131, FP: 0.0009587126370869471, FN: 0.6257175660160735\n","Epoch [5/10], Train Loss: 0.0334, Train Acc: 99.03%, Val Loss: 0.0359, Val Acc: 98.96%\n","TP: 0.47416762342135477, TN: 0.997625618235252, FP: 0.0023743817647480466, FN: 0.5258323765786452\n","Epoch [6/10], Train Loss: 0.0320, Train Acc: 99.05%, Val Loss: 0.0318, Val Acc: 99.08%\n","TP: 0.46096440872560274, TN: 0.9990412873629131, FP: 0.0009587126370869471, FN: 0.5390355912743973\n","Epoch [7/10], Train Loss: 0.0307, Train Acc: 99.10%, Val Loss: 0.0331, Val Acc: 99.03%\n","TP: 0.5011481056257175, TN: 0.9979481757580102, FP: 0.0020518242419898217, FN: 0.49885189437428246\n","Epoch [8/10], Train Loss: 0.0297, Train Acc: 99.13%, Val Loss: 0.0311, Val Acc: 99.12%\n","TP: 0.4672789896670494, TN: 0.9994086445416099, FP: 0.0005913554583900796, FN: 0.5327210103329506\n","Epoch [9/10], Train Loss: 0.0290, Train Acc: 99.15%, Val Loss: 0.0305, Val Acc: 99.13%\n","TP: 0.5086107921928817, TN: 0.9988620887391585, FP: 0.0011379112608415167, FN: 0.49138920780711826\n","Epoch [10/10], Train Loss: 0.0282, Train Acc: 99.17%, Val Loss: 0.0306, Val Acc: 99.12%\n","TP: 0.473593570608496, TN: 0.9992473657802308, FP: 0.0007526342197691922, FN: 0.5264064293915041\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0526, Train Acc: 98.59%, Val Loss: 0.0447, Val Acc: 98.76%\n","TP: 0.2261768082663605, TN: 0.9994982393577464, FP: 0.0005017606422536221, FN: 0.7738231917336394\n","Epoch [2/10], Train Loss: 0.0423, Train Acc: 98.81%, Val Loss: 0.0394, Val Acc: 98.90%\n","TP: 0.3266360505166475, TN: 0.9993011191054324, FP: 0.0006988808945675451, FN: 0.6733639494833524\n","Epoch [3/10], Train Loss: 0.0387, Train Acc: 98.91%, Val Loss: 0.0369, Val Acc: 98.95%\n","TP: 0.4115958668197474, TN: 0.9985663981649896, FP: 0.001433601835010349, FN: 0.5884041331802525\n","Epoch [4/10], Train Loss: 0.0361, Train Acc: 98.95%, Val Loss: 0.0353, Val Acc: 98.99%\n","TP: 0.4070034443168771, TN: 0.9989606386696175, FP: 0.001039361330382503, FN: 0.5929965556831228\n","Epoch [5/10], Train Loss: 0.0344, Train Acc: 99.00%, Val Loss: 0.0345, Val Acc: 99.01%\n","TP: 0.41102181400688864, TN: 0.9991577589219314, FP: 0.0008422410780685799, FN: 0.5889781859931114\n","Epoch [6/10], Train Loss: 0.0328, Train Acc: 99.04%, Val Loss: 0.0340, Val Acc: 99.03%\n","TP: 0.41446613088404133, TN: 0.9993100791169013, FP: 0.0006899208830987303, FN: 0.5855338691159586\n","Epoch [7/10], Train Loss: 0.0314, Train Acc: 99.08%, Val Loss: 0.0312, Val Acc: 99.09%\n","TP: 0.5241102181400689, TN: 0.9981721576603618, FP: 0.0018278423396381948, FN: 0.47588978185993114\n","Epoch [8/10], Train Loss: 0.0304, Train Acc: 99.10%, Val Loss: 0.0308, Val Acc: 99.09%\n","TP: 0.5258323765786452, TN: 0.998207997706237, FP: 0.001792002293762936, FN: 0.47416762342135477\n","Epoch [9/10], Train Loss: 0.0294, Train Acc: 99.14%, Val Loss: 0.0309, Val Acc: 99.10%\n","TP: 0.5275545350172216, TN: 0.9981990376947683, FP: 0.0018009623052317506, FN: 0.4724454649827784\n","Epoch [10/10], Train Loss: 0.0286, Train Acc: 99.16%, Val Loss: 0.0294, Val Acc: 99.15%\n","TP: 0.5137772675086107, TN: 0.9989427186466798, FP: 0.0010572813533201322, FN: 0.4862227324913892\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-eff9d210d121>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-eff9d210d121>:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-eff9d210d121>:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0521, Train Acc: 98.62%, Val Loss: 0.0452, Val Acc: 98.71%\n","TP: 0.256601607347876, TN: 0.9984857580617703, FP: 0.001514241938229681, FN: 0.743398392652124\n","Epoch [2/10], Train Loss: 0.0420, Train Acc: 98.82%, Val Loss: 0.0409, Val Acc: 98.84%\n","TP: 0.39035591274397247, TN: 0.9977331170983899, FP: 0.0022668829016101143, FN: 0.6096440872560276\n","Epoch [3/10], Train Loss: 0.0383, Train Acc: 98.90%, Val Loss: 0.0380, Val Acc: 98.95%\n","TP: 0.4150401836969001, TN: 0.9984767980503015, FP: 0.0015232019496984957, FN: 0.5849598163030999\n","Epoch [4/10], Train Loss: 0.0355, Train Acc: 98.99%, Val Loss: 0.0370, Val Acc: 98.90%\n","TP: 0.40470723306544204, TN: 0.998118397591549, FP: 0.0018816024084510829, FN: 0.595292766934558\n","Epoch [5/10], Train Loss: 0.0338, Train Acc: 99.02%, Val Loss: 0.0328, Val Acc: 99.06%\n","TP: 0.4701492537313433, TN: 0.9987724784287724, FP: 0.001227521571227611, FN: 0.5298507462686567\n","Epoch [6/10], Train Loss: 0.0323, Train Acc: 99.07%, Val Loss: 0.0334, Val Acc: 99.03%\n","TP: 0.4626865671641791, TN: 0.9985395181305832, FP: 0.001460481869416793, FN: 0.5373134328358209\n","Epoch [7/10], Train Loss: 0.0311, Train Acc: 99.09%, Val Loss: 0.0329, Val Acc: 99.05%\n","TP: 0.5177956371986223, TN: 0.9978675172704221, FP: 0.002132482729577894, FN: 0.48220436280137774\n","Epoch [8/10], Train Loss: 0.0301, Train Acc: 99.12%, Val Loss: 0.0317, Val Acc: 99.07%\n","TP: 0.5137772675086107, TN: 0.9981811176718306, FP: 0.00181888232816938, FN: 0.4862227324913892\n","Epoch [9/10], Train Loss: 0.0294, Train Acc: 99.13%, Val Loss: 0.0306, Val Acc: 99.11%\n","TP: 0.47876004592422505, TN: 0.9991039988531185, FP: 0.000896001146881468, FN: 0.521239954075775\n","Epoch [10/10], Train Loss: 0.0287, Train Acc: 99.15%, Val Loss: 0.0309, Val Acc: 99.09%\n","TP: 0.4833524684270953, TN: 0.9988172784861165, FP: 0.0011827215138835378, FN: 0.5166475315729047\n","Testing - Loss: 0.0309, Acc: 99.09%, TP: 1039, TN: 139352, FP: 146, FN: 1150\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"owUqJqFnCPka"},"id":"owUqJqFnCPka","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6JlGCH7ZCRMu"},"id":"6JlGCH7ZCRMu","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}