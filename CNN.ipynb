{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24199,"status":"ok","timestamp":1683819198742,"user":{"displayName":"William Cai","userId":"15768919470381419406"},"user_tz":420},"id":"zpKXzIWAoxjt","outputId":"4a9fb4c7-5f83-440d-89a2-b73358fd3438"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment2/'\n","FOLDERNAME = '/content/drive/MyDrive/Stanford Research/honor thesis for Ephysics/ephysics project/'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","# This downloads the CIFAR-10 dataset to your Drive\n","# if it doesn't already exist.\n","# %cd /content/drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n","# !bash get_datasets.sh\n","# %cd /content/drive/My\\ Drive/$FOLDERNAME"],"id":"zpKXzIWAoxjt"},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":356,"status":"ok","timestamp":1683819215559,"user":{"displayName":"William Cai","userId":"15768919470381419406"},"user_tz":420},"id":"6a97252d"},"outputs":[],"source":["# !pip install pymatgen\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import style\n","\n","import sklearn\n","import csv\n","import pandas as pd\n","# import pymatgen as mg\n","import random\n","import os\n","from bisect import bisect_left   \n","from sklearn import preprocessing\n","from sklearn.utils import Bunch\n","from sklearn import svm\n","# from mp_api.client import MPRester\n","\n","#from sklearn import datasets, svm\n","from sklearn.svm import SVC\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.preprocessing import StandardScaler\n","\n","import time\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.model_selection import StratifiedKFold\n","\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import StratifiedKFold\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_recall_curve, confusion_matrix\n","\n","\n","style.use(\"ggplot\")"],"id":"6a97252d"},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683819215929,"user":{"displayName":"William Cai","userId":"15768919470381419406"},"user_tz":420},"id":"e4c8578b"},"outputs":[],"source":["#shuffles dataset\n","def format_dataset(X, y, size = -1):\n","    random.seed(a=5)\n","    length = np.size(y)\n","    indices = np.arange(length)\n","    np.random.shuffle(indices)\n","    new_X = []\n","    new_y = []\n","    for x in indices:\n","        new_X.append(X[x])\n","        new_y.append(y[x])\n","    if size == -1:\n","        return Bunch(data=new_X, target=new_y)\n","    return Bunch(data=new_X[0:size], target=new_y[0:size])\n","\n","#pos, neg are lists\n","def get_labels(pos, neg):\n","    y = []\n","    for i in range(len(pos)):\n","        y.append(1)\n","    for i in range(len(neg)):\n","        y.append(0)\n","    return np.array(y)\n","\n","\n","def calculate_classification_rates(predictions, labels):\n","    \"\"\"\n","    Calculates the classification rates based on the predictions and labels.\n","\n","    Args:\n","    - predictions: NumPy array of predicted values (shape: [n_samples])\n","    - labels: List of true labels (length: n_samples)\n","\n","    Returns:\n","    - true_positive_rate: Float, true positive rate (TPR) or sensitivity\n","    - false_positive_rate: Float, false positive rate (FPR)\n","    - true_negative_rate: Float, true negative rate (TNR) or specificity\n","    - false_negative_rate: Float, false negative rate (FNR)\n","    \"\"\"\n","\n","    # Convert labels to NumPy array for easier manipulation\n","    labels = np.array(labels)\n","\n","    # Calculate the number of true positive, false positive, true negative, and false negative\n","    true_positive = np.sum((predictions == 1) & (labels == 1))\n","    false_positive = np.sum((predictions == 1) & (labels == 0))\n","    true_negative = np.sum((predictions == 0) & (labels == 0))\n","    false_negative = np.sum((predictions == 0) & (labels == 1))\n","\n","    # Calculate the rates\n","    true_positive_rate = true_positive / (true_positive + false_negative)\n","    false_positive_rate = false_positive / (false_positive + true_negative)\n","    true_negative_rate = true_negative / (true_negative + false_positive)\n","    false_negative_rate = false_negative / (false_negative + true_positive)\n","\n","    return true_positive_rate, false_positive_rate, true_negative_rate, false_negative_rate"],"id":"e4c8578b"},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":474,"status":"ok","timestamp":1683819240093,"user":{"displayName":"William Cai","userId":"15768919470381419406"},"user_tz":420},"id":"owUqJqFnCPka"},"outputs":[],"source":["# Define the CNN model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv1d(112, 64, kernel_size=1)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc = nn.Linear(64, 2)  # Assuming binary classification\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = x.view(x.size(0), -1)  # Flatten the tensor\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        return x"],"id":"owUqJqFnCPka"},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6JlGCH7ZCRMu","executionInfo":{"status":"ok","timestamp":1683820925413,"user_tz":420,"elapsed":1565904,"user":{"displayName":"William Cai","userId":"15768919470381419406"}},"outputId":"38b993c3-716f-4539-81ef-7220de477ba0"},"outputs":[{"output_type":"stream","name":"stdout","text":["experiment with multiple:1\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.1244, Train Acc: 95.81%, Val Loss: 0.0290, Val Acc: 99.25%\n","TP: 0.9850230414746544, TN: 1.0, FP: 0.0, FN: 0.014976958525345621\n","Epoch [2/10], Train Loss: 0.0242, Train Acc: 99.46%, Val Loss: 0.0145, Val Acc: 99.71%\n","TP: 0.9942396313364056, TN: 1.0, FP: 0.0, FN: 0.00576036866359447\n","Epoch [3/10], Train Loss: 0.0154, Train Acc: 99.56%, Val Loss: 0.0128, Val Acc: 99.71%\n","TP: 0.9942396313364056, TN: 1.0, FP: 0.0, FN: 0.00576036866359447\n","Epoch [4/10], Train Loss: 0.0122, Train Acc: 99.63%, Val Loss: 0.0105, Val Acc: 99.74%\n","TP: 0.9953917050691244, TN: 0.9994292237442922, FP: 0.0005707762557077625, FN: 0.004608294930875576\n","Epoch [5/10], Train Loss: 0.0108, Train Acc: 99.70%, Val Loss: 0.0101, Val Acc: 99.91%\n","TP: 0.9982718894009217, TN: 1.0, FP: 0.0, FN: 0.0017281105990783411\n","Epoch [6/10], Train Loss: 0.0078, Train Acc: 99.79%, Val Loss: 0.0076, Val Acc: 99.91%\n","TP: 0.9982718894009217, TN: 1.0, FP: 0.0, FN: 0.0017281105990783411\n","Epoch [7/10], Train Loss: 0.0072, Train Acc: 99.77%, Val Loss: 0.0098, Val Acc: 99.74%\n","TP: 0.994815668202765, TN: 1.0, FP: 0.0, FN: 0.005184331797235023\n","Epoch [8/10], Train Loss: 0.0054, Train Acc: 99.84%, Val Loss: 0.0082, Val Acc: 99.91%\n","TP: 0.9982718894009217, TN: 1.0, FP: 0.0, FN: 0.0017281105990783411\n","Epoch [9/10], Train Loss: 0.0046, Train Acc: 99.91%, Val Loss: 0.0087, Val Acc: 99.86%\n","TP: 0.9976958525345622, TN: 0.9994292237442922, FP: 0.0005707762557077625, FN: 0.002304147465437788\n","Epoch [10/10], Train Loss: 0.0051, Train Acc: 99.84%, Val Loss: 0.0092, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.1240, Train Acc: 95.60%, Val Loss: 0.0279, Val Acc: 99.23%\n","TP: 0.9913594470046083, TN: 0.9931506849315068, FP: 0.00684931506849315, FN: 0.008640552995391706\n","Epoch [2/10], Train Loss: 0.0262, Train Acc: 99.30%, Val Loss: 0.0114, Val Acc: 99.74%\n","TP: 0.994815668202765, TN: 1.0, FP: 0.0, FN: 0.005184331797235023\n","Epoch [3/10], Train Loss: 0.0177, Train Acc: 99.49%, Val Loss: 0.0087, Val Acc: 99.71%\n","TP: 0.9942396313364056, TN: 1.0, FP: 0.0, FN: 0.00576036866359447\n","Epoch [4/10], Train Loss: 0.0137, Train Acc: 99.64%, Val Loss: 0.0052, Val Acc: 99.83%\n","TP: 0.9965437788018433, TN: 1.0, FP: 0.0, FN: 0.0034562211981566822\n","Epoch [5/10], Train Loss: 0.0096, Train Acc: 99.70%, Val Loss: 0.0050, Val Acc: 99.89%\n","TP: 0.9982718894009217, TN: 0.9994292237442922, FP: 0.0005707762557077625, FN: 0.0017281105990783411\n","Epoch [6/10], Train Loss: 0.0083, Train Acc: 99.73%, Val Loss: 0.0050, Val Acc: 99.91%\n","TP: 0.9982718894009217, TN: 1.0, FP: 0.0, FN: 0.0017281105990783411\n","Epoch [7/10], Train Loss: 0.0070, Train Acc: 99.77%, Val Loss: 0.0056, Val Acc: 99.89%\n","TP: 0.9976958525345622, TN: 1.0, FP: 0.0, FN: 0.002304147465437788\n","Epoch [8/10], Train Loss: 0.0067, Train Acc: 99.76%, Val Loss: 0.0051, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n","Epoch [9/10], Train Loss: 0.0050, Train Acc: 99.87%, Val Loss: 0.0084, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n","Epoch [10/10], Train Loss: 0.0065, Train Acc: 99.81%, Val Loss: 0.0072, Val Acc: 99.91%\n","TP: 0.9982718894009217, TN: 1.0, FP: 0.0, FN: 0.0017281105990783411\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.1290, Train Acc: 95.38%, Val Loss: 0.0233, Val Acc: 99.51%\n","TP: 0.9902130109383995, TN: 1.0, FP: 0.0, FN: 0.00978698906160046\n","Epoch [2/10], Train Loss: 0.0268, Train Acc: 99.30%, Val Loss: 0.0131, Val Acc: 99.63%\n","TP: 0.9925158318940702, TN: 1.0, FP: 0.0, FN: 0.007484168105929764\n","Epoch [3/10], Train Loss: 0.0177, Train Acc: 99.53%, Val Loss: 0.0086, Val Acc: 99.80%\n","TP: 0.9959700633275763, TN: 1.0, FP: 0.0, FN: 0.004029936672423719\n","Epoch [4/10], Train Loss: 0.0127, Train Acc: 99.67%, Val Loss: 0.0070, Val Acc: 99.77%\n","TP: 0.9953943580886586, TN: 1.0, FP: 0.0, FN: 0.004605641911341394\n","Epoch [5/10], Train Loss: 0.0099, Train Acc: 99.73%, Val Loss: 0.0054, Val Acc: 99.86%\n","TP: 0.9971214738054116, TN: 1.0, FP: 0.0, FN: 0.0028785261945883708\n","Epoch [6/10], Train Loss: 0.0078, Train Acc: 99.76%, Val Loss: 0.0041, Val Acc: 99.94%\n","TP: 0.9988485895221646, TN: 1.0, FP: 0.0, FN: 0.0011514104778353484\n","Epoch [7/10], Train Loss: 0.0064, Train Acc: 99.81%, Val Loss: 0.0036, Val Acc: 99.94%\n","TP: 0.9988485895221646, TN: 1.0, FP: 0.0, FN: 0.0011514104778353484\n","Epoch [8/10], Train Loss: 0.0059, Train Acc: 99.81%, Val Loss: 0.0033, Val Acc: 99.94%\n","TP: 0.9988485895221646, TN: 1.0, FP: 0.0, FN: 0.0011514104778353484\n","Epoch [9/10], Train Loss: 0.0052, Train Acc: 99.86%, Val Loss: 0.0037, Val Acc: 99.94%\n","TP: 0.9988485895221646, TN: 1.0, FP: 0.0, FN: 0.0011514104778353484\n","Epoch [10/10], Train Loss: 0.0047, Train Acc: 99.87%, Val Loss: 0.0032, Val Acc: 99.94%\n","TP: 0.9988485895221646, TN: 1.0, FP: 0.0, FN: 0.0011514104778353484\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.1215, Train Acc: 96.03%, Val Loss: 0.0275, Val Acc: 99.25%\n","TP: 0.9855990783410138, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.014400921658986175\n","Epoch [2/10], Train Loss: 0.0293, Train Acc: 99.12%, Val Loss: 0.0132, Val Acc: 99.74%\n","TP: 0.994815668202765, TN: 1.0, FP: 0.0, FN: 0.005184331797235023\n","Epoch [3/10], Train Loss: 0.0180, Train Acc: 99.48%, Val Loss: 0.0109, Val Acc: 99.71%\n","TP: 0.9959677419354839, TN: 0.9982866933181039, FP: 0.0017133066818960593, FN: 0.004032258064516129\n","Epoch [4/10], Train Loss: 0.0145, Train Acc: 99.59%, Val Loss: 0.0067, Val Acc: 99.83%\n","TP: 0.9965437788018433, TN: 1.0, FP: 0.0, FN: 0.0034562211981566822\n","Epoch [5/10], Train Loss: 0.0105, Train Acc: 99.69%, Val Loss: 0.0051, Val Acc: 99.80%\n","TP: 0.9971198156682027, TN: 0.9988577955454027, FP: 0.001142204454597373, FN: 0.002880184331797235\n","Epoch [6/10], Train Loss: 0.0083, Train Acc: 99.72%, Val Loss: 0.0039, Val Acc: 99.91%\n","TP: 0.9982718894009217, TN: 1.0, FP: 0.0, FN: 0.0017281105990783411\n","Epoch [7/10], Train Loss: 0.0078, Train Acc: 99.77%, Val Loss: 0.0051, Val Acc: 99.80%\n","TP: 0.9959677419354839, TN: 1.0, FP: 0.0, FN: 0.004032258064516129\n","Epoch [8/10], Train Loss: 0.0075, Train Acc: 99.79%, Val Loss: 0.0023, Val Acc: 99.89%\n","TP: 0.9976958525345622, TN: 1.0, FP: 0.0, FN: 0.002304147465437788\n","Epoch [9/10], Train Loss: 0.0087, Train Acc: 99.81%, Val Loss: 0.0029, Val Acc: 99.94%\n","TP: 0.9988479262672811, TN: 1.0, FP: 0.0, FN: 0.001152073732718894\n","Epoch [10/10], Train Loss: 0.0051, Train Acc: 99.84%, Val Loss: 0.0029, Val Acc: 99.94%\n","TP: 0.9994239631336406, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.000576036866359447\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.1222, Train Acc: 95.86%, Val Loss: 0.0309, Val Acc: 99.17%\n","TP: 0.9855990783410138, TN: 0.9977155910908052, FP: 0.002284408909194746, FN: 0.014400921658986175\n","Epoch [2/10], Train Loss: 0.0241, Train Acc: 99.37%, Val Loss: 0.0200, Val Acc: 99.48%\n","TP: 0.9896313364055299, TN: 1.0, FP: 0.0, FN: 0.010368663594470046\n","Epoch [3/10], Train Loss: 0.0158, Train Acc: 99.51%, Val Loss: 0.0146, Val Acc: 99.54%\n","TP: 0.9913594470046083, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.008640552995391706\n","Epoch [4/10], Train Loss: 0.0113, Train Acc: 99.73%, Val Loss: 0.0136, Val Acc: 99.57%\n","TP: 0.9913594470046083, TN: 1.0, FP: 0.0, FN: 0.008640552995391706\n","Epoch [5/10], Train Loss: 0.0090, Train Acc: 99.73%, Val Loss: 0.0099, Val Acc: 99.63%\n","TP: 0.993663594470046, TN: 0.9988577955454027, FP: 0.001142204454597373, FN: 0.006336405529953917\n","Epoch [6/10], Train Loss: 0.0095, Train Acc: 99.72%, Val Loss: 0.0103, Val Acc: 99.60%\n","TP: 0.9919354838709677, TN: 1.0, FP: 0.0, FN: 0.008064516129032258\n","Epoch [7/10], Train Loss: 0.0067, Train Acc: 99.78%, Val Loss: 0.0078, Val Acc: 99.66%\n","TP: 0.993663594470046, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.006336405529953917\n","Epoch [8/10], Train Loss: 0.0083, Train Acc: 99.71%, Val Loss: 0.0055, Val Acc: 99.86%\n","TP: 0.9976958525345622, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.002304147465437788\n","Epoch [9/10], Train Loss: 0.0044, Train Acc: 99.88%, Val Loss: 0.0046, Val Acc: 99.80%\n","TP: 0.9965437788018433, TN: 0.9994288977727013, FP: 0.0005711022272986865, FN: 0.0034562211981566822\n","Epoch [10/10], Train Loss: 0.0047, Train Acc: 99.88%, Val Loss: 0.0065, Val Acc: 99.71%\n","TP: 0.9942396313364056, TN: 1.0, FP: 0.0, FN: 0.00576036866359447\n","Testing - Loss: 0.0061, Acc: 99.75%, TP: 2207, TN: 2142, FP: 0, FN: 11\n","experiment with multiple:4\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0514, Train Acc: 98.60%, Val Loss: 0.0093, Val Acc: 99.78%\n","TP: 0.9948776323278316, TN: 0.9985638374263966, FP: 0.0014361625736033319, FN: 0.005122367672168469\n","Epoch [2/10], Train Loss: 0.0103, Train Acc: 99.71%, Val Loss: 0.0035, Val Acc: 99.90%\n","TP: 0.9948776323278316, TN: 1.0, FP: 0.0, FN: 0.005122367672168469\n","Epoch [3/10], Train Loss: 0.0078, Train Acc: 99.81%, Val Loss: 0.0029, Val Acc: 99.92%\n","TP: 0.9960159362549801, TN: 1.0, FP: 0.0, FN: 0.00398406374501992\n","Epoch [4/10], Train Loss: 0.0064, Train Acc: 99.79%, Val Loss: 0.0017, Val Acc: 99.98%\n","TP: 0.9988616960728515, TN: 1.0, FP: 0.0, FN: 0.0011383039271485487\n","Epoch [5/10], Train Loss: 0.0041, Train Acc: 99.89%, Val Loss: 0.0017, Val Acc: 99.95%\n","TP: 0.9977233921457029, TN: 1.0, FP: 0.0, FN: 0.0022766078542970974\n","Epoch [6/10], Train Loss: 0.0051, Train Acc: 99.84%, Val Loss: 0.0026, Val Acc: 99.95%\n","TP: 0.9977233921457029, TN: 1.0, FP: 0.0, FN: 0.0022766078542970974\n","Epoch [7/10], Train Loss: 0.0034, Train Acc: 99.89%, Val Loss: 0.0038, Val Acc: 99.98%\n","TP: 0.9988616960728515, TN: 1.0, FP: 0.0, FN: 0.0011383039271485487\n","Epoch [8/10], Train Loss: 0.0033, Train Acc: 99.91%, Val Loss: 0.0038, Val Acc: 99.98%\n","TP: 0.9988616960728515, TN: 1.0, FP: 0.0, FN: 0.0011383039271485487\n","Epoch [9/10], Train Loss: 0.0029, Train Acc: 99.90%, Val Loss: 0.0061, Val Acc: 99.94%\n","TP: 0.9971542401821286, TN: 1.0, FP: 0.0, FN: 0.0028457598178713715\n","Epoch [10/10], Train Loss: 0.0030, Train Acc: 99.90%, Val Loss: 0.0064, Val Acc: 99.94%\n","TP: 0.9988616960728515, TN: 0.999569151227919, FP: 0.00043084877208099956, FN: 0.0011383039271485487\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0524, Train Acc: 98.38%, Val Loss: 0.0103, Val Acc: 99.71%\n","TP: 0.9869020501138952, TN: 0.9997127674852794, FP: 0.0002872325147206664, FN: 0.013097949886104784\n","Epoch [2/10], Train Loss: 0.0100, Train Acc: 99.73%, Val Loss: 0.0067, Val Acc: 99.83%\n","TP: 0.9920273348519362, TN: 0.9998563837426396, FP: 0.0001436162573603332, FN: 0.007972665148063782\n","Epoch [3/10], Train Loss: 0.0065, Train Acc: 99.80%, Val Loss: 0.0053, Val Acc: 99.86%\n","TP: 0.9931662870159453, TN: 1.0, FP: 0.0, FN: 0.00683371298405467\n","Epoch [4/10], Train Loss: 0.0057, Train Acc: 99.85%, Val Loss: 0.0046, Val Acc: 99.86%\n","TP: 0.9931662870159453, TN: 1.0, FP: 0.0, FN: 0.00683371298405467\n","Epoch [5/10], Train Loss: 0.0052, Train Acc: 99.82%, Val Loss: 0.0039, Val Acc: 99.87%\n","TP: 0.9937357630979499, TN: 1.0, FP: 0.0, FN: 0.006264236902050114\n","Epoch [6/10], Train Loss: 0.0035, Train Acc: 99.88%, Val Loss: 0.0039, Val Acc: 99.87%\n","TP: 0.9937357630979499, TN: 1.0, FP: 0.0, FN: 0.006264236902050114\n","Epoch [7/10], Train Loss: 0.0043, Train Acc: 99.89%, Val Loss: 0.0024, Val Acc: 99.92%\n","TP: 0.9960136674259681, TN: 1.0, FP: 0.0, FN: 0.003986332574031891\n","Epoch [8/10], Train Loss: 0.0028, Train Acc: 99.91%, Val Loss: 0.0026, Val Acc: 99.93%\n","TP: 0.9965831435079726, TN: 1.0, FP: 0.0, FN: 0.003416856492027335\n","Epoch [9/10], Train Loss: 0.0037, Train Acc: 99.90%, Val Loss: 0.0022, Val Acc: 99.94%\n","TP: 0.9971526195899773, TN: 1.0, FP: 0.0, FN: 0.0028473804100227792\n","Epoch [10/10], Train Loss: 0.0027, Train Acc: 99.93%, Val Loss: 0.0026, Val Acc: 99.93%\n","TP: 0.9965831435079726, TN: 1.0, FP: 0.0, FN: 0.003416856492027335\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0499, Train Acc: 98.62%, Val Loss: 0.0080, Val Acc: 99.77%\n","TP: 0.9886104783599089, TN: 1.0, FP: 0.0, FN: 0.011389521640091117\n","Epoch [2/10], Train Loss: 0.0100, Train Acc: 99.74%, Val Loss: 0.0068, Val Acc: 99.79%\n","TP: 0.989749430523918, TN: 1.0, FP: 0.0, FN: 0.010250569476082005\n","Epoch [3/10], Train Loss: 0.0080, Train Acc: 99.80%, Val Loss: 0.0041, Val Acc: 99.87%\n","TP: 0.9965831435079726, TN: 0.9992819187131984, FP: 0.0007180812868016659, FN: 0.003416856492027335\n","Epoch [4/10], Train Loss: 0.0053, Train Acc: 99.84%, Val Loss: 0.0033, Val Acc: 99.85%\n","TP: 0.9925968109339408, TN: 1.0, FP: 0.0, FN: 0.007403189066059226\n","Epoch [5/10], Train Loss: 0.0046, Train Acc: 99.87%, Val Loss: 0.0025, Val Acc: 99.90%\n","TP: 0.994874715261959, TN: 1.0, FP: 0.0, FN: 0.005125284738041002\n","Epoch [6/10], Train Loss: 0.0044, Train Acc: 99.87%, Val Loss: 0.0027, Val Acc: 99.92%\n","TP: 0.9960136674259681, TN: 1.0, FP: 0.0, FN: 0.003986332574031891\n","Epoch [7/10], Train Loss: 0.0037, Train Acc: 99.88%, Val Loss: 0.0022, Val Acc: 99.92%\n","TP: 0.9960136674259681, TN: 1.0, FP: 0.0, FN: 0.003986332574031891\n","Epoch [8/10], Train Loss: 0.0039, Train Acc: 99.88%, Val Loss: 0.0028, Val Acc: 99.89%\n","TP: 0.9943052391799544, TN: 1.0, FP: 0.0, FN: 0.0056947608200455585\n","Epoch [9/10], Train Loss: 0.0031, Train Acc: 99.90%, Val Loss: 0.0013, Val Acc: 99.95%\n","TP: 0.9977220956719818, TN: 1.0, FP: 0.0, FN: 0.002277904328018223\n","Epoch [10/10], Train Loss: 0.0034, Train Acc: 99.90%, Val Loss: 0.0015, Val Acc: 99.95%\n","TP: 0.9977220956719818, TN: 1.0, FP: 0.0, FN: 0.002277904328018223\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0569, Train Acc: 98.16%, Val Loss: 0.0095, Val Acc: 99.75%\n","TP: 0.9874715261958997, TN: 1.0, FP: 0.0, FN: 0.012528473804100227\n","Epoch [2/10], Train Loss: 0.0110, Train Acc: 99.69%, Val Loss: 0.0063, Val Acc: 99.87%\n","TP: 0.9937357630979499, TN: 1.0, FP: 0.0, FN: 0.006264236902050114\n","Epoch [3/10], Train Loss: 0.0070, Train Acc: 99.80%, Val Loss: 0.0048, Val Acc: 99.93%\n","TP: 0.9965831435079726, TN: 1.0, FP: 0.0, FN: 0.003416856492027335\n","Epoch [4/10], Train Loss: 0.0051, Train Acc: 99.83%, Val Loss: 0.0046, Val Acc: 99.93%\n","TP: 0.9965831435079726, TN: 1.0, FP: 0.0, FN: 0.003416856492027335\n","Epoch [5/10], Train Loss: 0.0049, Train Acc: 99.84%, Val Loss: 0.0047, Val Acc: 99.97%\n","TP: 0.9982915717539863, TN: 1.0, FP: 0.0, FN: 0.0017084282460136675\n","Epoch [6/10], Train Loss: 0.0040, Train Acc: 99.88%, Val Loss: 0.0051, Val Acc: 99.93%\n","TP: 0.9965831435079726, TN: 1.0, FP: 0.0, FN: 0.003416856492027335\n","Epoch [7/10], Train Loss: 0.0044, Train Acc: 99.85%, Val Loss: 0.0051, Val Acc: 99.97%\n","TP: 0.9982915717539863, TN: 1.0, FP: 0.0, FN: 0.0017084282460136675\n","Epoch [8/10], Train Loss: 0.0050, Train Acc: 99.85%, Val Loss: 0.0054, Val Acc: 99.94%\n","TP: 0.9971526195899773, TN: 1.0, FP: 0.0, FN: 0.0028473804100227792\n","Epoch [9/10], Train Loss: 0.0034, Train Acc: 99.88%, Val Loss: 0.0061, Val Acc: 99.92%\n","TP: 0.9982915717539863, TN: 0.9994255349705586, FP: 0.0005744650294413328, FN: 0.0017084282460136675\n","Epoch [10/10], Train Loss: 0.0035, Train Acc: 99.89%, Val Loss: 0.0047, Val Acc: 99.97%\n","TP: 0.9982915717539863, TN: 1.0, FP: 0.0, FN: 0.0017084282460136675\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0499, Train Acc: 98.69%, Val Loss: 0.0100, Val Acc: 99.67%\n","TP: 0.983494593056346, TN: 1.0, FP: 0.0, FN: 0.016505406943653957\n","Epoch [2/10], Train Loss: 0.0099, Train Acc: 99.72%, Val Loss: 0.0049, Val Acc: 99.85%\n","TP: 0.9926010244735345, TN: 1.0, FP: 0.0, FN: 0.007398975526465566\n","Epoch [3/10], Train Loss: 0.0072, Train Acc: 99.79%, Val Loss: 0.0052, Val Acc: 99.82%\n","TP: 0.9908935685828116, TN: 1.0, FP: 0.0, FN: 0.00910643141718839\n","Epoch [4/10], Train Loss: 0.0063, Train Acc: 99.84%, Val Loss: 0.0030, Val Acc: 99.91%\n","TP: 0.9954467842914058, TN: 1.0, FP: 0.0, FN: 0.004553215708594195\n","Epoch [5/10], Train Loss: 0.0054, Train Acc: 99.85%, Val Loss: 0.0022, Val Acc: 99.94%\n","TP: 0.9982925441092771, TN: 0.9997127262280954, FP: 0.0002872737719046251, FN: 0.001707455890722823\n","Epoch [6/10], Train Loss: 0.0038, Train Acc: 99.88%, Val Loss: 0.0025, Val Acc: 99.92%\n","TP: 0.9960159362549801, TN: 1.0, FP: 0.0, FN: 0.00398406374501992\n","Epoch [7/10], Train Loss: 0.0043, Train Acc: 99.85%, Val Loss: 0.0013, Val Acc: 99.95%\n","TP: 0.9977233921457029, TN: 1.0, FP: 0.0, FN: 0.0022766078542970974\n","Epoch [8/10], Train Loss: 0.0039, Train Acc: 99.88%, Val Loss: 0.0011, Val Acc: 99.97%\n","TP: 0.9982925441092771, TN: 1.0, FP: 0.0, FN: 0.001707455890722823\n","Epoch [9/10], Train Loss: 0.0039, Train Acc: 99.88%, Val Loss: 0.0009, Val Acc: 99.97%\n","TP: 0.9982925441092771, TN: 1.0, FP: 0.0, FN: 0.001707455890722823\n","Epoch [10/10], Train Loss: 0.0037, Train Acc: 99.92%, Val Loss: 0.0010, Val Acc: 99.95%\n","TP: 0.9977233921457029, TN: 1.0, FP: 0.0, FN: 0.0022766078542970974\n","Testing - Loss: 0.0025, Acc: 99.94%, TP: 2110, TN: 8782, FP: 0, FN: 7\n","experiment with multiple:16\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.1179, Train Acc: 96.21%, Val Loss: 0.0743, Val Acc: 97.51%\n","TP: 0.6231470923603193, TN: 0.997275204359673, FP: 0.0027247956403269754, FN: 0.3768529076396807\n","Epoch [2/10], Train Loss: 0.0832, Train Acc: 97.37%, Val Loss: 0.0615, Val Acc: 97.94%\n","TP: 0.685290763968073, TN: 0.9978846981213251, FP: 0.002115301878674889, FN: 0.314709236031927\n","Epoch [3/10], Train Loss: 0.0738, Train Acc: 97.65%, Val Loss: 0.0571, Val Acc: 97.98%\n","TP: 0.6767388825541619, TN: 0.9988168650509106, FP: 0.0011831349490893446, FN: 0.3232611174458381\n","Epoch [4/10], Train Loss: 0.0687, Train Acc: 97.88%, Val Loss: 0.0512, Val Acc: 98.34%\n","TP: 0.7366020524515393, TN: 0.9988885701993403, FP: 0.0011114298006596874, FN: 0.2633979475484607\n","Epoch [5/10], Train Loss: 0.0656, Train Acc: 98.00%, Val Loss: 0.0498, Val Acc: 98.35%\n","TP: 0.7377423033067275, TN: 0.9989244227735551, FP: 0.0010755772264448588, FN: 0.26225769669327254\n","Epoch [6/10], Train Loss: 0.0628, Train Acc: 98.04%, Val Loss: 0.0471, Val Acc: 98.62%\n","TP: 0.7924743443557583, TN: 0.9983507815861179, FP: 0.0016492184138821168, FN: 0.20752565564424175\n","Epoch [7/10], Train Loss: 0.0604, Train Acc: 98.14%, Val Loss: 0.0455, Val Acc: 98.58%\n","TP: 0.7713797035347777, TN: 0.9992829485157034, FP: 0.0007170514842965725, FN: 0.22862029646522236\n","Epoch [8/10], Train Loss: 0.0611, Train Acc: 98.19%, Val Loss: 0.0440, Val Acc: 98.55%\n","TP: 0.7639680729760547, TN: 0.9993905062383479, FP: 0.0006094937616520866, FN: 0.23603192702394526\n","Epoch [9/10], Train Loss: 0.0577, Train Acc: 98.18%, Val Loss: 0.0429, Val Acc: 98.67%\n","TP: 0.7896237172177879, TN: 0.9991395382188442, FP: 0.000860461781155887, FN: 0.2103762827822121\n","Epoch [10/10], Train Loss: 0.0559, Train Acc: 98.27%, Val Loss: 0.0418, Val Acc: 98.76%\n","TP: 0.806157354618016, TN: 0.9989961279219848, FP: 0.0010038720780152016, FN: 0.19384264538198404\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.1174, Train Acc: 96.17%, Val Loss: 0.0763, Val Acc: 97.67%\n","TP: 0.6505131128848347, TN: 0.9972392528055645, FP: 0.0027607471944354808, FN: 0.34948688711516535\n","Epoch [2/10], Train Loss: 0.0809, Train Acc: 97.44%, Val Loss: 0.0658, Val Acc: 97.75%\n","TP: 0.644811858608894, TN: 0.9984224301746083, FP: 0.0015775698253917034, FN: 0.35518814139110605\n","Epoch [3/10], Train Loss: 0.0724, Train Acc: 97.71%, Val Loss: 0.0581, Val Acc: 98.20%\n","TP: 0.7206385404789054, TN: 0.9983865763149403, FP: 0.0016134236850596966, FN: 0.27936145952109465\n","Epoch [4/10], Train Loss: 0.0674, Train Acc: 97.86%, Val Loss: 0.0568, Val Acc: 98.16%\n","TP: 0.7269099201824402, TN: 0.9976336452619124, FP: 0.0023663547380875553, FN: 0.27309007981755984\n","Epoch [5/10], Train Loss: 0.0633, Train Acc: 98.02%, Val Loss: 0.0531, Val Acc: 98.42%\n","TP: 0.7616875712656784, TN: 0.9982431608762683, FP: 0.0017568391237316697, FN: 0.23831242873432154\n","Epoch [6/10], Train Loss: 0.0606, Train Acc: 98.13%, Val Loss: 0.0504, Val Acc: 98.45%\n","TP: 0.7616875712656784, TN: 0.9985299917536122, FP: 0.0014700082463877237, FN: 0.23831242873432154\n","Epoch [7/10], Train Loss: 0.0583, Train Acc: 98.22%, Val Loss: 0.0505, Val Acc: 98.38%\n","TP: 0.741733181299886, TN: 0.9990677996486321, FP: 0.0009322003513678247, FN: 0.25826681870011403\n","Epoch [8/10], Train Loss: 0.0557, Train Acc: 98.25%, Val Loss: 0.0494, Val Acc: 98.44%\n","TP: 0.7594070695553021, TN: 0.9986016994729483, FP: 0.0013983005270517372, FN: 0.24059293044469784\n","Epoch [9/10], Train Loss: 0.0548, Train Acc: 98.32%, Val Loss: 0.0464, Val Acc: 98.57%\n","TP: 0.766248574686431, TN: 0.9994621921049801, FP: 0.0005378078950198989, FN: 0.233751425313569\n","Epoch [10/10], Train Loss: 0.0532, Train Acc: 98.33%, Val Loss: 0.0458, Val Acc: 98.56%\n","TP: 0.7690992018244014, TN: 0.9991753612276362, FP: 0.000824638772363845, FN: 0.23090079817559864\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.1157, Train Acc: 96.30%, Val Loss: 0.0765, Val Acc: 97.63%\n","TP: 0.6459521094640821, TN: 0.9970241296475566, FP: 0.0029758703524434406, FN: 0.3540478905359179\n","Epoch [2/10], Train Loss: 0.0804, Train Acc: 97.47%, Val Loss: 0.0653, Val Acc: 98.04%\n","TP: 0.7092360319270239, TN: 0.9974543759635724, FP: 0.0025456240364275214, FN: 0.29076396807297605\n","Epoch [3/10], Train Loss: 0.0714, Train Acc: 97.74%, Val Loss: 0.0572, Val Acc: 98.27%\n","TP: 0.7309007981755986, TN: 0.9985658456132803, FP: 0.0014341543867197304, FN: 0.2690992018244014\n","Epoch [4/10], Train Loss: 0.0661, Train Acc: 97.89%, Val Loss: 0.0601, Val Acc: 98.19%\n","TP: 0.7052451539338654, TN: 0.9993187766663081, FP: 0.0006812233336918719, FN: 0.29475484606613456\n","Epoch [5/10], Train Loss: 0.0623, Train Acc: 98.02%, Val Loss: 0.0512, Val Acc: 98.46%\n","TP: 0.7793614595210946, TN: 0.9975260836829085, FP: 0.002473916317091535, FN: 0.22063854047890535\n","Epoch [6/10], Train Loss: 0.0596, Train Acc: 98.14%, Val Loss: 0.0497, Val Acc: 98.56%\n","TP: 0.7633979475484607, TN: 0.9995338998243161, FP: 0.00046610017568391235, FN: 0.23660205245153934\n","Epoch [7/10], Train Loss: 0.0581, Train Acc: 98.20%, Val Loss: 0.0480, Val Acc: 98.61%\n","TP: 0.7839224629418472, TN: 0.9987809687712882, FP: 0.0012190312287117709, FN: 0.2160775370581528\n","Epoch [8/10], Train Loss: 0.0567, Train Acc: 98.25%, Val Loss: 0.0488, Val Acc: 98.61%\n","TP: 0.7776510832383124, TN: 0.9992112150873041, FP: 0.0007887849126958517, FN: 0.22234891676168758\n","Epoch [9/10], Train Loss: 0.0544, Train Acc: 98.30%, Val Loss: 0.0466, Val Acc: 98.69%\n","TP: 0.7930444697833523, TN: 0.9990677996486321, FP: 0.0009322003513678247, FN: 0.20695553021664767\n","Epoch [10/10], Train Loss: 0.0545, Train Acc: 98.33%, Val Loss: 0.0448, Val Acc: 98.72%\n","TP: 0.8015963511972634, TN: 0.9988885303502922, FP: 0.001111469649707791, FN: 0.19840364880273662\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.1199, Train Acc: 96.10%, Val Loss: 0.0745, Val Acc: 97.58%\n","TP: 0.6282782212086659, TN: 0.9976336452619124, FP: 0.0023663547380875553, FN: 0.3717217787913341\n","Epoch [2/10], Train Loss: 0.0807, Train Acc: 97.44%, Val Loss: 0.0686, Val Acc: 97.81%\n","TP: 0.6733181299885975, TN: 0.9972392528055645, FP: 0.0027607471944354808, FN: 0.32668187001140253\n","Epoch [3/10], Train Loss: 0.0719, Train Acc: 97.73%, Val Loss: 0.0574, Val Acc: 98.16%\n","TP: 0.7360319270239453, TN: 0.9970958373668926, FP: 0.002904162633107454, FN: 0.26396807297605474\n","Epoch [4/10], Train Loss: 0.0666, Train Acc: 97.94%, Val Loss: 0.0544, Val Acc: 98.25%\n","TP: 0.7212086659064995, TN: 0.9989602380696282, FP: 0.0010397619303718045, FN: 0.27879133409350054\n","Epoch [5/10], Train Loss: 0.0631, Train Acc: 98.06%, Val Loss: 0.0537, Val Acc: 98.34%\n","TP: 0.7348916761687572, TN: 0.9989960919292962, FP: 0.0010039080707038113, FN: 0.2651083238312429\n","Epoch [6/10], Train Loss: 0.0598, Train Acc: 98.16%, Val Loss: 0.0489, Val Acc: 98.48%\n","TP: 0.7628278221208666, TN: 0.9987451149116202, FP: 0.001254885088379764, FN: 0.23717217787913342\n","Epoch [7/10], Train Loss: 0.0575, Train Acc: 98.22%, Val Loss: 0.0492, Val Acc: 98.46%\n","TP: 0.7480045610034207, TN: 0.9994980459646481, FP: 0.0005019540353519056, FN: 0.2519954389965792\n","Epoch [8/10], Train Loss: 0.0570, Train Acc: 98.25%, Val Loss: 0.0447, Val Acc: 98.64%\n","TP: 0.7850627137970353, TN: 0.9990677996486321, FP: 0.0009322003513678247, FN: 0.21493728620296465\n","Epoch [9/10], Train Loss: 0.0544, Train Acc: 98.32%, Val Loss: 0.0439, Val Acc: 98.61%\n","TP: 0.7822120866590649, TN: 0.9988885303502922, FP: 0.001111469649707791, FN: 0.217787913340935\n","Epoch [10/10], Train Loss: 0.0530, Train Acc: 98.39%, Val Loss: 0.0432, Val Acc: 98.75%\n","TP: 0.7993158494868872, TN: 0.9993187766663081, FP: 0.0006812233336918719, FN: 0.2006841505131129\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.1177, Train Acc: 96.15%, Val Loss: 0.0724, Val Acc: 97.73%\n","TP: 0.6493728620296465, TN: 0.9979563299989244, FP: 0.0020436700010756158, FN: 0.3506271379703535\n","Epoch [2/10], Train Loss: 0.0821, Train Acc: 97.41%, Val Loss: 0.0624, Val Acc: 98.01%\n","TP: 0.6955530216647663, TN: 0.9979563299989244, FP: 0.0020436700010756158, FN: 0.30444697833523376\n","Epoch [3/10], Train Loss: 0.0738, Train Acc: 97.70%, Val Loss: 0.0545, Val Acc: 98.37%\n","TP: 0.7474344355758267, TN: 0.9985299917536122, FP: 0.0014700082463877237, FN: 0.2525655644241733\n","Epoch [4/10], Train Loss: 0.0680, Train Acc: 97.86%, Val Loss: 0.0534, Val Acc: 98.31%\n","TP: 0.7633979475484607, TN: 0.9969524219282205, FP: 0.003047578071779427, FN: 0.23660205245153934\n","Epoch [5/10], Train Loss: 0.0654, Train Acc: 97.97%, Val Loss: 0.0525, Val Acc: 98.38%\n","TP: 0.7924743443557583, TN: 0.9958409522785128, FP: 0.004159047721487218, FN: 0.20752565564424175\n","Epoch [6/10], Train Loss: 0.0622, Train Acc: 98.06%, Val Loss: 0.0473, Val Acc: 98.55%\n","TP: 0.7776510832383124, TN: 0.9985658456132803, FP: 0.0014341543867197304, FN: 0.22234891676168758\n","Epoch [7/10], Train Loss: 0.0610, Train Acc: 98.09%, Val Loss: 0.0460, Val Acc: 98.56%\n","TP: 0.7651083238312428, TN: 0.9994263382453121, FP: 0.0005736617546878922, FN: 0.2348916761687571\n","Epoch [8/10], Train Loss: 0.0571, Train Acc: 98.22%, Val Loss: 0.0438, Val Acc: 98.68%\n","TP: 0.7970353477765109, TN: 0.9987809687712882, FP: 0.0012190312287117709, FN: 0.20296465222348917\n","Epoch [9/10], Train Loss: 0.0557, Train Acc: 98.25%, Val Loss: 0.0429, Val Acc: 98.74%\n","TP: 0.8181299885974914, TN: 0.9980638915779284, FP: 0.001936108422071636, FN: 0.18187001140250855\n","Epoch [10/10], Train Loss: 0.0556, Train Acc: 98.33%, Val Loss: 0.0451, Val Acc: 98.51%\n","TP: 0.774230330672748, TN: 0.9983507224552723, FP: 0.00164927754472769, FN: 0.22576966932725198\n","Testing - Loss: 0.0467, Acc: 98.57%, TP: 1640, TN: 34888, FP: 40, FN: 489\n","experiment with multiple:64\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0599, Train Acc: 98.48%, Val Loss: 0.0495, Val Acc: 98.52%\n","TP: 0.04075774971297359, TN: 0.9999731202064368, FP: 2.6879793563185434e-05, FN: 0.9592422502870264\n","Epoch [2/10], Train Loss: 0.0524, Train Acc: 98.58%, Val Loss: 0.0471, Val Acc: 98.65%\n","TP: 0.13260619977037888, TN: 0.9998208013762454, FP: 0.00017919862375456958, FN: 0.8673938002296211\n","Epoch [3/10], Train Loss: 0.0505, Train Acc: 98.63%, Val Loss: 0.0484, Val Acc: 98.57%\n","TP: 0.07290470723306544, TN: 0.9999910400688122, FP: 8.959931187728478e-06, FN: 0.9270952927669346\n","Epoch [4/10], Train Loss: 0.0489, Train Acc: 98.66%, Val Loss: 0.0449, Val Acc: 98.72%\n","TP: 0.1727898966704937, TN: 0.999901440756935, FP: 9.855924306501326e-05, FN: 0.8272101033295063\n","Epoch [5/10], Train Loss: 0.0481, Train Acc: 98.68%, Val Loss: 0.0430, Val Acc: 98.73%\n","TP: 0.182548794489093, TN: 0.9998387212386209, FP: 0.0001612787613791126, FN: 0.817451205510907\n","Epoch [6/10], Train Loss: 0.0473, Train Acc: 98.68%, Val Loss: 0.0442, Val Acc: 98.72%\n","TP: 0.17221584385763491, TN: 0.9999104006881228, FP: 8.959931187728479e-05, FN: 0.8277841561423651\n","Epoch [7/10], Train Loss: 0.0468, Train Acc: 98.71%, Val Loss: 0.0426, Val Acc: 98.75%\n","TP: 0.19747416762342135, TN: 0.9998745609633718, FP: 0.0001254390366281987, FN: 0.8025258323765786\n","Epoch [8/10], Train Loss: 0.0460, Train Acc: 98.73%, Val Loss: 0.0434, Val Acc: 98.75%\n","TP: 0.1928817451205511, TN: 0.9999104006881228, FP: 8.959931187728479e-05, FN: 0.8071182548794489\n","Epoch [9/10], Train Loss: 0.0456, Train Acc: 98.73%, Val Loss: 0.0405, Val Acc: 98.81%\n","TP: 0.24052812858783007, TN: 0.999767041789119, FP: 0.00023295821088094044, FN: 0.7594718714121699\n","Epoch [10/10], Train Loss: 0.0453, Train Acc: 98.76%, Val Loss: 0.0420, Val Acc: 98.80%\n","TP: 0.22789896670493687, TN: 0.9998835208945596, FP: 0.00011647910544047022, FN: 0.7721010332950632\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0612, Train Acc: 98.45%, Val Loss: 0.0489, Val Acc: 98.58%\n","TP: 0.08495981630309989, TN: 0.999901440756935, FP: 9.855924306501326e-05, FN: 0.9150401836969001\n","Epoch [2/10], Train Loss: 0.0525, Train Acc: 98.58%, Val Loss: 0.0458, Val Acc: 98.61%\n","TP: 0.09758897818599312, TN: 0.999964160275249, FP: 3.583972475091391e-05, FN: 0.9024110218140069\n","Epoch [3/10], Train Loss: 0.0505, Train Acc: 98.61%, Val Loss: 0.0456, Val Acc: 98.70%\n","TP: 0.16073478760045926, TN: 0.9999193606193104, FP: 8.06393806895563e-05, FN: 0.8392652123995408\n","Epoch [4/10], Train Loss: 0.0492, Train Acc: 98.64%, Val Loss: 0.0443, Val Acc: 98.70%\n","TP: 0.16475315729047071, TN: 0.999865601032184, FP: 0.00013439896781592718, FN: 0.8352468427095293\n","Epoch [5/10], Train Loss: 0.0480, Train Acc: 98.68%, Val Loss: 0.0421, Val Acc: 98.77%\n","TP: 0.21239954075774972, TN: 0.9998208013762454, FP: 0.00017919862375456958, FN: 0.7876004592422503\n","Epoch [6/10], Train Loss: 0.0474, Train Acc: 98.68%, Val Loss: 0.0419, Val Acc: 98.81%\n","TP: 0.24741676234213547, TN: 0.999704322270805, FP: 0.0002956777291950398, FN: 0.7525832376578645\n","Epoch [7/10], Train Loss: 0.0469, Train Acc: 98.71%, Val Loss: 0.0415, Val Acc: 98.79%\n","TP: 0.23076923076923078, TN: 0.9997222421331804, FP: 0.0002777578668195828, FN: 0.7692307692307693\n","Epoch [8/10], Train Loss: 0.0463, Train Acc: 98.71%, Val Loss: 0.0412, Val Acc: 98.81%\n","TP: 0.24110218140068887, TN: 0.9997222421331804, FP: 0.0002777578668195828, FN: 0.7588978185993112\n","Epoch [9/10], Train Loss: 0.0463, Train Acc: 98.72%, Val Loss: 0.0412, Val Acc: 98.79%\n","TP: 0.22043628013777267, TN: 0.9998297613074332, FP: 0.00017023869256684108, FN: 0.7795637198622273\n","Epoch [10/10], Train Loss: 0.0450, Train Acc: 98.76%, Val Loss: 0.0415, Val Acc: 98.78%\n","TP: 0.21354764638346727, TN: 0.9998387212386209, FP: 0.0001612787613791126, FN: 0.7864523536165328\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0599, Train Acc: 98.47%, Val Loss: 0.0523, Val Acc: 98.53%\n","TP: 0.04649827784156142, TN: 0.9999731202064368, FP: 2.6879793563185434e-05, FN: 0.9535017221584385\n","Epoch [2/10], Train Loss: 0.0521, Train Acc: 98.59%, Val Loss: 0.0483, Val Acc: 98.64%\n","TP: 0.1182548794489093, TN: 0.9999462404128736, FP: 5.375958712637087e-05, FN: 0.8817451205510907\n","Epoch [3/10], Train Loss: 0.0504, Train Acc: 98.63%, Val Loss: 0.0458, Val Acc: 98.72%\n","TP: 0.1791044776119403, TN: 0.9997849616514946, FP: 0.00021503834850548347, FN: 0.8208955223880597\n","Epoch [4/10], Train Loss: 0.0485, Train Acc: 98.66%, Val Loss: 0.0452, Val Acc: 98.70%\n","TP: 0.1584385763490241, TN: 0.9998924808257472, FP: 0.00010751917425274174, FN: 0.8415614236509759\n","Epoch [5/10], Train Loss: 0.0475, Train Acc: 98.68%, Val Loss: 0.0444, Val Acc: 98.70%\n","TP: 0.16704936854190586, TN: 0.9997849616514946, FP: 0.00021503834850548347, FN: 0.8329506314580941\n","Epoch [6/10], Train Loss: 0.0469, Train Acc: 98.70%, Val Loss: 0.0436, Val Acc: 98.75%\n","TP: 0.19747416762342135, TN: 0.9997939215826822, FP: 0.000206078417317755, FN: 0.8025258323765786\n","Epoch [7/10], Train Loss: 0.0466, Train Acc: 98.72%, Val Loss: 0.0427, Val Acc: 98.79%\n","TP: 0.22101033295063147, TN: 0.9998297613074332, FP: 0.00017023869256684108, FN: 0.7789896670493686\n","Epoch [8/10], Train Loss: 0.0458, Train Acc: 98.73%, Val Loss: 0.0428, Val Acc: 98.80%\n","TP: 0.22847301951779564, TN: 0.9998476811698086, FP: 0.00015231883019138412, FN: 0.7715269804822044\n","Epoch [9/10], Train Loss: 0.0455, Train Acc: 98.75%, Val Loss: 0.0414, Val Acc: 98.80%\n","TP: 0.22789896670493687, TN: 0.999865601032184, FP: 0.00013439896781592718, FN: 0.7721010332950632\n","Epoch [10/10], Train Loss: 0.0453, Train Acc: 98.75%, Val Loss: 0.0411, Val Acc: 98.80%\n","TP: 0.23076923076923078, TN: 0.9998208013762454, FP: 0.00017919862375456958, FN: 0.7692307692307693\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0601, Train Acc: 98.48%, Val Loss: 0.0498, Val Acc: 98.54%\n","TP: 0.04879448909299656, TN: 1.0, FP: 0.0, FN: 0.9512055109070034\n","Epoch [2/10], Train Loss: 0.0521, Train Acc: 98.59%, Val Loss: 0.0477, Val Acc: 98.62%\n","TP: 0.10562571756601608, TN: 0.9999820799770623, FP: 1.792002293762936e-05, FN: 0.894374282433984\n","Epoch [3/10], Train Loss: 0.0506, Train Acc: 98.63%, Val Loss: 0.0449, Val Acc: 98.69%\n","TP: 0.15097588978185994, TN: 0.9999283199082495, FP: 7.168009175051744e-05, FN: 0.8490241102181401\n","Epoch [4/10], Train Loss: 0.0487, Train Acc: 98.67%, Val Loss: 0.0427, Val Acc: 98.74%\n","TP: 0.19345579793340986, TN: 0.9997939197362172, FP: 0.00020608026378273763, FN: 0.8065442020665902\n","Epoch [5/10], Train Loss: 0.0478, Train Acc: 98.68%, Val Loss: 0.0437, Val Acc: 98.74%\n","TP: 0.18714121699196326, TN: 0.9998476798050302, FP: 0.00015232019496984957, FN: 0.8128587830080367\n","Epoch [6/10], Train Loss: 0.0471, Train Acc: 98.70%, Val Loss: 0.0425, Val Acc: 98.73%\n","TP: 0.19058553386911595, TN: 0.999758079690342, FP: 0.00024192030965799636, FN: 0.8094144661308841\n","Epoch [7/10], Train Loss: 0.0466, Train Acc: 98.73%, Val Loss: 0.0422, Val Acc: 98.76%\n","TP: 0.22445464982778415, TN: 0.9994892793462775, FP: 0.0005107206537224367, FN: 0.7755453501722158\n","Epoch [8/10], Train Loss: 0.0462, Train Acc: 98.73%, Val Loss: 0.0410, Val Acc: 98.77%\n","TP: 0.21412169919632607, TN: 0.9997759997132797, FP: 0.000224000286720367, FN: 0.7858783008036739\n","Epoch [9/10], Train Loss: 0.0460, Train Acc: 98.75%, Val Loss: 0.0415, Val Acc: 98.79%\n","TP: 0.21871412169919632, TN: 0.9998655998279677, FP: 0.0001344001720322202, FN: 0.7812858783008036\n","Epoch [10/10], Train Loss: 0.0450, Train Acc: 98.76%, Val Loss: 0.0400, Val Acc: 98.82%\n","TP: 0.24397244546498278, TN: 0.9997670397018108, FP: 0.00023296029818918167, FN: 0.7560275545350172\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6851e15e6d95>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","<ipython-input-6-6851e15e6d95>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","<ipython-input-6-6851e15e6d95>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.0601, Train Acc: 98.47%, Val Loss: 0.0498, Val Acc: 98.57%\n","TP: 0.07175660160734787, TN: 0.9999462399311871, FP: 5.376006881288808e-05, FN: 0.9282433983926521\n","Epoch [2/10], Train Loss: 0.0522, Train Acc: 98.59%, Val Loss: 0.0477, Val Acc: 98.65%\n","TP: 0.13605051664753157, TN: 0.9998028797476861, FP: 0.00019712025231392297, FN: 0.8639494833524685\n","Epoch [3/10], Train Loss: 0.0503, Train Acc: 98.62%, Val Loss: 0.0463, Val Acc: 98.66%\n","TP: 0.13030998851894374, TN: 0.9999372799197183, FP: 6.272008028170276e-05, FN: 0.8696900114810563\n","Epoch [4/10], Train Loss: 0.0488, Train Acc: 98.66%, Val Loss: 0.0455, Val Acc: 98.70%\n","TP: 0.16130884041331803, TN: 0.9998655998279677, FP: 0.0001344001720322202, FN: 0.838691159586682\n","Epoch [5/10], Train Loss: 0.0481, Train Acc: 98.68%, Val Loss: 0.0432, Val Acc: 98.76%\n","TP: 0.20780711825487944, TN: 0.9998207997706237, FP: 0.0001792002293762936, FN: 0.7921928817451206\n","Epoch [6/10], Train Loss: 0.0471, Train Acc: 98.69%, Val Loss: 0.0429, Val Acc: 98.74%\n","TP: 0.1928817451205511, TN: 0.9998297597820925, FP: 0.00017024021790747892, FN: 0.8071182548794489\n","Epoch [7/10], Train Loss: 0.0467, Train Acc: 98.70%, Val Loss: 0.0414, Val Acc: 98.80%\n","TP: 0.2330654420206659, TN: 0.9998118397591549, FP: 0.00018816024084510828, FN: 0.7669345579793341\n","Epoch [8/10], Train Loss: 0.0462, Train Acc: 98.73%, Val Loss: 0.0423, Val Acc: 98.77%\n","TP: 0.20436280137772675, TN: 0.9999014398738431, FP: 9.856012615696148e-05, FN: 0.7956371986222732\n","Epoch [9/10], Train Loss: 0.0455, Train Acc: 98.74%, Val Loss: 0.0413, Val Acc: 98.80%\n","TP: 0.23019517795637198, TN: 0.9998207997706237, FP: 0.0001792002293762936, FN: 0.769804822043628\n","Epoch [10/10], Train Loss: 0.0448, Train Acc: 98.77%, Val Loss: 0.0410, Val Acc: 98.82%\n","TP: 0.2365097588978186, TN: 0.9998924798623742, FP: 0.00010752013762577616, FN: 0.7634902411021814\n","Testing - Loss: 0.0398, Acc: 98.77%, TP: 477, TN: 139472, FP: 26, FN: 1712\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["multipliers = [1,4, 16, 64] #1, 2, 4, 8, 16, 32, 64, 128\n","test_accs = []\n","test_losses = []\n","for multip in multipliers:\n","  print('experiment with multiple:' + str(multip))\n","  ## loading data\n","  X_pos = np.load(FOLDERNAME + '/partial_perfect_in_icsd.npy')\n","  X_neg = np.load(FOLDERNAME + '/not_in_icsd_proofread.npy')\n","  X_neg = X_neg[:10899*multip, :]\n","\n","  #concatenate the features together and scale\n","  X = np.concatenate((X_pos, X_neg), axis = 0)\n","  std_scale=preprocessing.StandardScaler().fit(X)\n","  X = std_scale.transform(X)\n","\n","  #get output label\n","  y = []\n","\n","  y=get_labels(X_pos,X_neg)\n","\n","  # Split the data into training and testing sets\n","  X_da_train, X_test, y_da_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n","\n","  # Check if GPU is available\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","  # Convert the data to PyTorch tensors and move them to the GPU\n","  X_da_train = torch.tensor(X_da_train, dtype=torch.float32).to(device)\n","  y_da_train = torch.tensor(y_da_train, dtype=torch.float32).to(device)\n","  X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n","  y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n","  skf = StratifiedKFold(n_splits=5, shuffle=True)\n","\n","  # Hyperparameters\n","  batch_size = 32\n","  learning_rate = 0.001\n","  num_epochs = 10\n","\n","  # Lists to store losses and accuracies\n","  train_losses = []\n","  val_losses = []\n","  train_accs = []\n","  val_accs = []\n","\n","  # Perform k-fold cross-validation\n","  for train_index, val_index in skf.split(X_da_train.cpu().numpy(), y_da_train.cpu().numpy()):\n","      # Move the data back to CPU\n","      X_train, X_val = X_da_train[train_index].cpu(), X_da_train[val_index].cpu()\n","      y_train, y_val = y_da_train[train_index].cpu(), y_da_train[val_index].cpu()\n","\n","      # Convert data to PyTorch tensors and move to device\n","      X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","      y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n","      X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n","      y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n","\n","      X_val = X_val.unsqueeze(1).permute(0,2,1)\n","\n","      # Create DataLoader for batch training\n","      train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n","      train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","      # Initialize model, loss function, and optimizer\n","      # Initialize the CNN model and move it to the GPU\n","      model = CNN().to(device)\n","\n","      # Define the loss function, optimizer, and learning rate\n","      criterion = nn.CrossEntropyLoss()\n","      optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","      # Training loop\n","      for epoch in range(num_epochs):\n","          model.train()\n","          running_loss = 0.0\n","          correct = 0\n","          total = 0\n","\n","          for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            \n","            inputs = inputs.unsqueeze(1).permute(0,2,1)\n","            # print(inputs.shape)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            \n","          \n","          # Compute training accuracy and loss\n","          train_acc = 100 * correct / total\n","          train_loss = running_loss / len(train_loader)\n","\n","          # Record training accuracy and loss\n","          train_accs.append(train_acc)\n","          train_losses.append(train_loss)\n","\n","          # Evaluation on validation set\n","          model.eval()\n","          with torch.no_grad():\n","            \n","            # print(X_val.shape)\n","            val_outputs = model(X_val)\n","            val_loss = criterion(val_outputs, y_val)\n","            _, val_predicted = torch.max(val_outputs.data, 1)\n","            val_acc = 100 * (val_predicted == y_val).sum().item() / y_val.size(0)\n","            # Record validation accuracy and loss\n","            val_accs.append(val_acc)\n","            val_losses.append(val_loss.item())\n","\n","            # Calculate confusion matrix\n","            val_true = y_val.cpu().numpy()\n","            val_pred = val_predicted.cpu().numpy()\n","            tn, fp, fn, tp = confusion_matrix(val_true, val_pred).ravel()\n","\n","            # Calculate rates\n","            val_tp_rate = tp / (tp + fn)\n","            val_tn_rate = tn / (tn + fp)\n","            val_fp_rate = fp / (fp + tn)\n","            val_fn_rate = fn / (fn + tp)\n","\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n","                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n","                  f\"Val Loss: {val_loss.item():.4f}, Val Acc: {val_acc:.2f}%\")\n","            print(f\"TP: {val_tp_rate}, \" f\"TN: {val_tn_rate}, \" f\"FP: {val_fp_rate}, \" f\"FN: {val_fn_rate}\")\n","  # Testing\n","  with torch.no_grad():\n","    X_test = X_test.unsqueeze(1).permute(0,2,1)\n","    test_outputs = model(X_test)\n","    y_test = y_test.long()\n","    test_loss = criterion(test_outputs, y_test)\n","    _, test_predicted = torch.max(test_outputs.data, 1)\n","    test_acc = 100 * (test_predicted == y_test).sum().item() / y_test.size(0)\n","    test_tp = ((test_predicted == 1) & (y_test == 1)).sum().item()\n","    test_tn = ((test_predicted == 0) & (y_test == 0)).sum().item()\n","    test_fp = ((test_predicted == 1) & (y_test == 0)).sum().item()\n","    test_fn = ((test_predicted == 0) & (y_test == 1)).sum().item()\n","    # Record testing accuracy and loss\n","    test_accs.append(test_acc)\n","    test_losses.append(test_loss.item())\n","\n","    print(f\"Testing - \"\n","          f\"Loss: {test_loss.item():.4f}, \"\n","          f\"Acc: {test_acc:.2f}%, \"\n","          f\"TP: {test_tp}, \"\n","          f\"TN: {test_tn}, \"\n","          f\"FP: {test_fp}, \"\n","          f\"FN: {test_fn}\")\n","    precision, recall, _ = precision_recall_curve(val_true, val_pred)\n","\n","    # Plot precision-recall curve\n","    plt.plot(recall, precision, label=f\"unlabel to label ratio {multip}:1\")\n","\n","# Plot random guessing line\n","plt.plot([0, 1], [0.5, 0.5], linestyle=\"--\", color=\"gray\", label=\"Random Guessing\")\n","\n","# Set plot properties\n","plt.xlabel(\"Recall\")\n","plt.ylabel(\"Precision\")\n","plt.title(\"Precision-Recall Curve\")\n","plt.legend()\n","\n","# Show the plot\n","plt.show()"],"id":"6JlGCH7ZCRMu"},{"cell_type":"code","execution_count":null,"metadata":{"id":"M09hM8f9Vh92"},"outputs":[],"source":[],"id":"M09hM8f9Vh92"}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":5}